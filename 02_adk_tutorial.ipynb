{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ADK Features\n",
        "\n",
        "- This notebook contains the key features of ADK that can help you build your custom agent.\n",
        "- Credit to lavinigam@"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:red\">**YOU NEED TO UPDATE YOUR PROJECT_ID AND LOCATION**</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:red\">**Verify google-adk version is 0.5.0**</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Version: 0.5.0\n"
          ]
        }
      ],
      "source": [
        "!uv pip show google-adk | grep Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Temp - to supress WARNING:google_genai.types:\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\", category=UserWarning, module=\"google.generativeai.types.content_types\"\n",
        ")  # Suppress harmless warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9y2tcqvOVWt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"hello-world-418507\"\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = LOCATION\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"TRUE\"  # Use Vertex AI API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73qeFgix6d0x"
      },
      "source": [
        "### LLM Agent with a Single Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp2U_FdrIl_d",
        "outputId": "f7c78468-2a5f-46ca-9bbf-3fcafcb92aec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent Response:  The capital of France is Paris.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google.adk.agents import LlmAgent\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel\n",
        "from google.adk.agents import Agent\n",
        "from google.genai import types\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "\n",
        "# Constant\n",
        "APP_NAME = \"capital_city_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"capital_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-exp\"\n",
        "\n",
        "\n",
        "# Define a simple tool\n",
        "def get_capital_city(country: str) -> str:\n",
        "    \"\"\"Retrieves the capital city of a given country.\n",
        "\n",
        "    Args:\n",
        "        country: The name of the country.\n",
        "\n",
        "    Returns:\n",
        "        The capital city of the country.\n",
        "    \"\"\"\n",
        "    country_capitals = {\n",
        "        \"united states\": \"washington, d.c.\",\n",
        "        \"canada\": \"ottawa\",\n",
        "        \"france\": \"paris\",\n",
        "    }\n",
        "    return country_capitals.get(country.lower(), \"Capital not found\")\n",
        "\n",
        "\n",
        "# Agent\n",
        "capital_agent = LlmAgent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=\"capital_agent\",\n",
        "    description=\"An agent that can retrieve the capital city of a country.\",\n",
        "    instruction=\"\"\"You are an agent that can retrieve the capital city of a country.\n",
        "    When a user provides a prompt, extract the country name.\n",
        "    Then, use the `get_capital_city` tool to retrieve the capital city for that country.\n",
        "    Finally, present the capital city to the user in a clear and concise manner.\n",
        "    \"\"\",\n",
        "    tools=[get_capital_city],\n",
        "    generate_content_config=types.GenerateContentConfig(\n",
        "        max_output_tokens=100,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=capital_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "def call_agent(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n",
        "\n",
        "\n",
        "call_agent(\"What is the capital of france?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SugbbRPE6QYL"
      },
      "source": [
        "### LLM Agent with a Input/Output Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K0gMttqXgn3",
        "outputId": "a9534934-f503-4477-cafc-0a5150b4a7ab"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "from pydantic import Field\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.genai import types\n",
        "\n",
        "# Constant\n",
        "APP_NAME = \"capital_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"capital_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "\n",
        "class InputSchema(BaseModel):\n",
        "    country: str = Field(description=\"The country to find the capital of.\")\n",
        "\n",
        "\n",
        "class OutputSchema(BaseModel):\n",
        "    capital: str = Field(description=\"The capital of the country.\")\n",
        "\n",
        "\n",
        "# Agent\n",
        "capital_agent = Agent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=AGENT_NAME,\n",
        "    instruction=\"\"\"You are a Capital Information Agent. Your task is to provide the capital of a given country.\n",
        "\n",
        "    When a user provides a prompt, extract the country name.\n",
        "    Then, respond with the capital of that country in the following JSON format:\n",
        "\n",
        "    \"\"\",\n",
        "    description=\"\"\"You are an agent who can tell the capital of a country.\"\"\",\n",
        "    disallow_transfer_to_peers=True,\n",
        "    disallow_transfer_to_parent=True,\n",
        "    input_schema=InputSchema,\n",
        "    output_schema=OutputSchema,\n",
        ")\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=capital_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "def call_agent(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n",
        "\n",
        "\n",
        "call_agent('{\"country\": \"France\"}')\n",
        "call_agent('{\"country\": \"Germany\"}')\n",
        "call_agent('{\"country\": \"Japan\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXOPByf86GYm"
      },
      "source": [
        "### LLM Agent with a output_key\n",
        "\n",
        "- You set `output_key` to store the key value pair into session state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2mV97Ctf_jF",
        "outputId": "4baa9e80-4754-4c97-9809-809661d471ed"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.agents import LlmAgent\n",
        "import json\n",
        "\n",
        "\n",
        "# Constant\n",
        "APP_NAME = \"capital_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"capital_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "# Agent\n",
        "capital_agent = Agent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=AGENT_NAME,\n",
        "    instruction=\"\"\"You are a Capital Information Agent. Your task is to provide the capital of a given country.\n",
        "\n",
        "    When a user provides a prompt, extract the country name.\n",
        "\n",
        "    \"\"\",\n",
        "    description=\"\"\"You are an agent who can tell the capital of a country.\"\"\",\n",
        "    output_key=\"capital_output\",\n",
        ")\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=capital_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "def call_agent(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n",
        "            print(\n",
        "                \"Session State:\",\n",
        "                session_service.get_session(\n",
        "                    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        "                ).state.get(\"capital_output\"),\n",
        "            )\n",
        "\n",
        "\n",
        "call_agent(\"What's the capital of France?\")\n",
        "call_agent(\"What's the capital of Germany?\")\n",
        "call_agent(\"What's the capital of Japan?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCUGzcWD59A3"
      },
      "source": [
        "### LLM Agent with a built_in_code_execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVXqH7O5jDTa",
        "outputId": "6bc8f1e9-dcae-4a96-d2fe-fec8c4909c76"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.agents import LlmAgent\n",
        "import json\n",
        "from google.adk.tools import built_in_code_execution\n",
        "\n",
        "# Constant\n",
        "APP_NAME = \"capital_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"capital_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "code_agent = LlmAgent(\n",
        "    name=\"code_execution_agent\",\n",
        "    model=GEMINI_2_FLASH,\n",
        "    tools=[built_in_code_execution],\n",
        "    instruction=\"Generate python code to solve the user's request. \"\n",
        "    \"If the user asks for a specific output, return the output of the code execution.\",\n",
        ")\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=code_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "def call_agent(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.content and event.content.parts:\n",
        "            for part in event.content.parts:\n",
        "                if part.text:\n",
        "                    print(f\"\\n--- Agent Response ---\\n{part.text}\\n\")\n",
        "        else:\n",
        "            print(f\"Event: {event}\")\n",
        "\n",
        "\n",
        "call_agent(\"what is 111 + 222\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E17fqZuaH1BM"
      },
      "source": [
        "### LLM Agent with a Multiple Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtFi_2ANHUN4",
        "outputId": "f4e8707c-d3a6-434f-e5e4-4de38e78adc1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.agents import LlmAgent\n",
        "\n",
        "# Constants\n",
        "APP_NAME = \"recipe_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"recipe_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "# --- Mock Data ---\n",
        "recipes = {\n",
        "    \"pasta carbonara\": {\n",
        "        \"ingredients\": [\n",
        "            \"pasta\",\n",
        "            \"eggs\",\n",
        "            \"guanciale\",\n",
        "            \"pecorino romano\",\n",
        "            \"black pepper\",\n",
        "        ],\n",
        "        \"dietary_restrictions\": [\"none\"],\n",
        "    },\n",
        "    \"chicken tikka masala\": {\n",
        "        \"ingredients\": [\"chicken\", \"yogurt\", \"ginger\", \"garlic\", \"masala blend\"],\n",
        "        \"dietary_restrictions\": [\"none\"],\n",
        "    },\n",
        "    \"vegan lentil soup\": {\n",
        "        \"ingredients\": [\"lentils\", \"carrots\", \"celery\", \"onion\", \"vegetable broth\"],\n",
        "        \"dietary_restrictions\": [\"vegan\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# --- Tools ---\n",
        "def search_recipes(keyword: str) -> str:\n",
        "    \"\"\"Searches for recipes based on a keyword.\n",
        "\n",
        "    Args:\n",
        "        keyword: The keyword to search for (e.g., ingredient).\n",
        "\n",
        "    Returns:\n",
        "        A string containing the names of matching recipes, or a message if no recipes are found.\n",
        "    \"\"\"\n",
        "    matching_recipes = [\n",
        "        recipe_name\n",
        "        for recipe_name, recipe_data in recipes.items()\n",
        "        if keyword.lower() in recipe_name.lower()\n",
        "        or keyword.lower() in recipe_data[\"ingredients\"]\n",
        "    ]\n",
        "    if matching_recipes:\n",
        "        return f\"Recipes matching '{keyword}': {', '.join(matching_recipes)}.\"\n",
        "    else:\n",
        "        return f\"No recipes found matching '{keyword}'.\"\n",
        "\n",
        "\n",
        "def check_dietary_restrictions(recipe_name: str, dietary_restriction: str) -> str:\n",
        "    \"\"\"Checks if a recipe is suitable for a given dietary restriction.\n",
        "\n",
        "    Args:\n",
        "        recipe_name: The name of the recipe to check.\n",
        "        dietary_restriction: The dietary restriction to check for (e.g., \"vegan\").\n",
        "\n",
        "    Returns:\n",
        "        A string indicating if the recipe is suitable or not.\n",
        "    \"\"\"\n",
        "    recipe_data = recipes.get(recipe_name.lower())\n",
        "    if recipe_data:\n",
        "        if dietary_restriction.lower() in recipe_data[\"dietary_restrictions\"]:\n",
        "            return f\"'{recipe_name}' is suitable for a '{dietary_restriction}' diet.\"\n",
        "        else:\n",
        "            return (\n",
        "                f\"'{recipe_name}' is not suitable for a '{dietary_restriction}' diet.\"\n",
        "            )\n",
        "    else:\n",
        "        return f\"Recipe '{recipe_name}' not found.\"\n",
        "\n",
        "\n",
        "def get_ingredient_list(recipe_name: str) -> str:\n",
        "    \"\"\"Returns a list of ingredients for a given recipe.\n",
        "\n",
        "    Args:\n",
        "        recipe_name: The name of the recipe.\n",
        "\n",
        "    Returns:\n",
        "        A string containing the list of ingredients, or a message if the recipe is not found.\n",
        "    \"\"\"\n",
        "    recipe_data = recipes.get(recipe_name.lower())\n",
        "    if recipe_data:\n",
        "        return (\n",
        "            f\"Ingredients for '{recipe_name}': {', '.join(recipe_data['ingredients'])}.\"\n",
        "        )\n",
        "    else:\n",
        "        return f\"Recipe '{recipe_name}' not found.\"\n",
        "\n",
        "\n",
        "# --- Agent ---\n",
        "recipe_agent = Agent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=AGENT_NAME,\n",
        "    instruction=\"\"\"You are a Recipe Agent. Your task is to help users find recipes and check their suitability for dietary restrictions.\n",
        "\n",
        "    You have access to three tools:\n",
        "    1. `search_recipes`: Use this tool to find recipes based on a keyword (e.g., ingredient).\n",
        "    2. `check_dietary_restrictions`: Use this tool to check if a recipe is suitable for a given dietary restriction.\n",
        "    3. `get_ingredient_list`: Use this tool to get a list of ingredients for a given recipe.\n",
        "\n",
        "    When a user provides a prompt, first determine what they are asking for.\n",
        "    - If they are asking for recipes based on a keyword, use the `search_recipes` tool.\n",
        "    - If they are asking if a recipe is suitable for a dietary restriction, use the `check_dietary_restrictions` tool.\n",
        "    - If they are asking for a list of ingredients for a recipe, use the `get_ingredient_list` tool.\n",
        "    Finally, present the information to the user in a clear and concise manner.\n",
        "    \"\"\",\n",
        "    description=\"\"\"An agent that can find recipes, check dietary restrictions, and list ingredients.\n",
        "    It has access to the `search_recipes`, `check_dietary_restrictions`, and `get_ingredient_list` tools.\"\"\",\n",
        "    tools=[\n",
        "        search_recipes,\n",
        "        check_dietary_restrictions,\n",
        "        get_ingredient_list,\n",
        "    ],\n",
        ")\n",
        "\n",
        "# --- Session and Runner ---\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=recipe_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# --- Agent Interaction ---\n",
        "def call_agent(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n",
        "\n",
        "\n",
        "call_agent(\"Find recipes with chicken.\")\n",
        "call_agent(\"Is pasta carbonara suitable for a vegan diet?\")\n",
        "call_agent(\"What are the ingredients in vegan lentil soup?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G6tlJhHR3FM"
      },
      "source": [
        "### LLM Agent with a Async Run\n",
        "\n",
        "- It is as simple as using `runner.run_async` instead of `runner.run`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urYEdu2MRvWg",
        "outputId": "ab6398ba-dd9f-4a31-f63b-fffe2a830aa1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.agents import LlmAgent\n",
        "\n",
        "\n",
        "# Constant\n",
        "APP_NAME = \"weather_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"weather_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "\n",
        "# Tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Retrieves weather information for the given city.\n",
        "\n",
        "    Args:\n",
        "        city: The name of the city for which to retrieve weather information.\n",
        "\n",
        "    Returns:\n",
        "        A string containing the weather information for the specified city,\n",
        "        or a message indicating that the weather information was not found.\n",
        "    \"\"\"\n",
        "    cities = {\n",
        "        \"chicago\": {\"temperature\": 25, \"condition\": \"sunny\", \"sky\": \"clear\"},\n",
        "        \"toronto\": {\"temperature\": 30, \"condition\": \"partly cloudy\", \"sky\": \"overcast\"},\n",
        "        \"chennai\": {\n",
        "            \"temperature\": 15,\n",
        "            \"condition\": \"rainy\",\n",
        "            \"sky\": \"cloudy\",\n",
        "        },  # Fixed typo: 'tempeerature' to 'temperature'\n",
        "    }\n",
        "\n",
        "    city_lower = city.lower()\n",
        "    if city_lower in cities:\n",
        "        weather_data = cities[city_lower]\n",
        "        return f\"Weather in {city} is {weather_data['temperature']} degrees Celsius, {weather_data['condition']} with a {weather_data['sky']} sky.\"\n",
        "    else:\n",
        "        return f\"Weather information for {city} not found.\"\n",
        "\n",
        "\n",
        "# Agent\n",
        "root_agent = Agent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=AGENT_NAME,\n",
        "    instruction=\"\"\"You are a Weather Information Agent. Your task is to provide weather information for a given city.\n",
        "\n",
        "    When a user provides a prompt, extract the city name.\n",
        "    Then, use the `get_weather` tool to retrieve the weather information for that city.\n",
        "    Finally, present the weather information to the user in a clear and concise manner.\"\"\",\n",
        "    description=\"\"\"You are an agent who can fetch weather information for a city.\n",
        "    You have access to the `get_weather` tool to accomplish this task.\"\"\",\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "async def call_agent_async(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    async for event in runner.run_async(\n",
        "        user_id=USER_ID, session_id=SESSION_ID, new_message=content\n",
        "    ):\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n",
        "\n",
        "\n",
        "await call_agent_async(\"What's the weather in toronto?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbq5jAVSVCUM"
      },
      "source": [
        "### LLM Agent with single sub-agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U9RE0gb0TFkg"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.agents import LlmAgent\n",
        "import asyncio\n",
        "\n",
        "# Constant\n",
        "APP_NAME = \"weather_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"weather_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "\n",
        "# Tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Retrieves weather information for the given city.\n",
        "\n",
        "    Args:\n",
        "        city: The name of the city for which to retrieve weather information.\n",
        "\n",
        "    Returns:\n",
        "        A string containing the weather information for the specified city,\n",
        "        or a message indicating that the weather information was not found.\n",
        "    \"\"\"\n",
        "    cities = {\n",
        "        \"chicago\": {\"temperature\": 25, \"condition\": \"sunny\", \"sky\": \"clear\"},\n",
        "        \"toronto\": {\"temperature\": 30, \"condition\": \"partly cloudy\", \"sky\": \"overcast\"},\n",
        "        \"chennai\": {\"temperature\": 15, \"condition\": \"rainy\", \"sky\": \"cloudy\"},\n",
        "    }\n",
        "\n",
        "    city_lower = city.lower()\n",
        "    if city_lower in cities:\n",
        "        weather_data = cities[city_lower]\n",
        "        return f\"Weather in {city} is {weather_data['temperature']} degrees Celsius, {weather_data['condition']} with a {weather_data['sky']} sky.\"\n",
        "    else:\n",
        "        return f\"Weather information for {city} not found.\"\n",
        "\n",
        "\n",
        "def get_greeting(name: str) -> str:\n",
        "    \"\"\"Greets the given name.\n",
        "\n",
        "    Args:\n",
        "        name: The name to greet.\n",
        "\n",
        "    Returns:\n",
        "        A greeting message.\n",
        "    \"\"\"\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "\n",
        "# Agent\n",
        "root_agent = LlmAgent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=\"root_agent\",\n",
        "    instruction=\"\"\"You are a helpful agent with tool and sub-agents.\n",
        "    - When user ask about weather, extract the city name, then use the `get_weather` tool to retrieve the weather information for that city.\n",
        "    - If the user asks for a greeting, transfer to the greeting_agent.\"\"\",\n",
        "    description=\"\"\"You are an agent who can fetch weather information for a city, and also greet a user.\"\"\",\n",
        "    tools=[get_weather],\n",
        "    # allow_transfer=True,\n",
        ")\n",
        "\n",
        "greeting_agent = LlmAgent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=\"greeting_agent\",\n",
        "    instruction=\"\"\"You are a Greeting Agent. Your task is to greet the user.\n",
        "\n",
        "    When a user provides a prompt, extract the name.\n",
        "    Then, use the `get_greeting` tool to greet the user.\n",
        "    Finally, present the greeting to the user in a clear and concise manner.\n",
        "    If the user asks for weather information, transfer to the weather agent.\"\"\",\n",
        "    description=\"\"\"You are an agent who can greet a user.\n",
        "    You have access to the `get_greeting` tool to accomplish this task.\"\"\",\n",
        "    tools=[get_greeting],\n",
        "    disallow_transfer_to_parent=True,\n",
        "    disallow_transfer_to_peers=True,\n",
        ")\n",
        "\n",
        "# Set parent-child relationship\n",
        "root_agent.sub_agents = [greeting_agent]\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "async def call_agent_async(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    async for event in runner.run_async(\n",
        "        user_id=USER_ID, session_id=SESSION_ID, new_message=content\n",
        "    ):\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_70TiFhAfP3Z",
        "outputId": "9cfeb22e-a07d-4bf0-91e0-182a662b6699"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"What's the weather in toronto?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7YvXK5afP0C",
        "outputId": "0411cab1-c4fe-40ea-a5c2-e49b17758513"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"Hello, Jimmy!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"What's the weather in chennai?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUiHdzpATx2H"
      },
      "source": [
        "### Weather Agent with multiple sub-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rOIYc49jTyHj"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Retrieves weather information for the given city.\n",
        "\n",
        "    Args:\n",
        "        city: The name of the city for which to retrieve weather information.\n",
        "\n",
        "    Returns:\n",
        "        A string containing the weather information for the specified city,\n",
        "        or a message indicating that the weather information was not found.\n",
        "    \"\"\"\n",
        "    cities = {\n",
        "        \"chicago\": {\"temperature\": 25, \"condition\": \"sunny\", \"sky\": \"clear\"},\n",
        "        \"toronto\": {\"temperature\": 30, \"condition\": \"partly cloudy\", \"sky\": \"overcast\"},\n",
        "        \"chennai\": {\"temperature\": 15, \"condition\": \"rainy\", \"sky\": \"cloudy\"},\n",
        "    }\n",
        "\n",
        "    city_lower = city.lower()\n",
        "    if city_lower in cities:\n",
        "        weather_data = cities[city_lower]\n",
        "        return f\"Weather in {city} is {weather_data['temperature']} degrees Celsius, {weather_data['condition']} with a {weather_data['sky']} sky.\"\n",
        "    else:\n",
        "        return f\"Weather information for {city} not found.\"\n",
        "\n",
        "\n",
        "# Tool for the Greeting Agent\n",
        "def say_hello(name: str = \"there\") -> str:\n",
        "    \"\"\"Provides a simple greeting.\"\"\"\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "\n",
        "# Tool for the Farewell Agent\n",
        "def say_goodbye() -> str:\n",
        "    \"\"\"Provides a simple farewell message.\"\"\"\n",
        "    return \"Goodbye! Have a great day.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX-ZKdrgT09N",
        "outputId": "c8602e47-5e64-4a79-8e72-1dc276face1e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# --- Import LlmAgent ---\n",
        "from google.adk.agents import LlmAgent\n",
        "import google.genai.types as types  # For Content/Part later\n",
        "\n",
        "# --- Agent Definitions ---\n",
        "AGENT_NAME_WEATHER = \"weather_agent\"\n",
        "AGENT_NAME_GREETING = \"greeting_agent\"\n",
        "AGENT_NAME_FAREWELL = \"farewell_agent\"\n",
        "MODEL_NAME = \"gemini-2.0-flash-001\"  # Use a recent flash model\n",
        "\n",
        "# --- Parent Agent: Weather ---\n",
        "root_agent = LlmAgent(\n",
        "    model=MODEL_NAME,\n",
        "    name=AGENT_NAME_WEATHER,\n",
        "    instruction=f\"\"\"You are the main Weather Agent in charge. Your primary responsibility is providing weather information.\n",
        "    - **IF** the user asks specifically about the weather (e.g., 'weather in city', 'forecast'), use the 'get_weather' tool YOURSELF. **DO NOT transfer weather requests.**\n",
        "    - **ONLY IF** the user gives a simple greeting (like 'Hi', 'Hello') with NO other request, transfer to the '{AGENT_NAME_GREETING}'.\n",
        "    - **ONLY IF** the user explicitly says goodbye (like 'Bye', 'See you'), transfer to the '{AGENT_NAME_FAREWELL}'.\n",
        "    - Handle only weather requests directly.\n",
        "    \"\"\",\n",
        "    description=\"Provides weather forecasts using 'get_weather'. Delegates greetings/farewells.\",\n",
        "    tools=[get_weather],\n",
        ")\n",
        "print(f\"Defined parent agent: {root_agent.name}\")\n",
        "\n",
        "\n",
        "# --- Child Agent 1: Greeting ---\n",
        "greeting_agent = LlmAgent(\n",
        "    model=MODEL_NAME,\n",
        "    name=AGENT_NAME_GREETING,\n",
        "    instruction=\"You are the Greeting Agent. Use the 'say_hello' tool to greet the user. Do nothing else.\",\n",
        "    description=\"Handles simple greetings using the 'say_hello' tool.\",\n",
        "    tools=[say_hello],\n",
        "    disallow_transfer_to_parent=True,\n",
        "    disallow_transfer_to_peers=True,\n",
        ")\n",
        "\n",
        "# --- Child Agent 2: Farewell ---\n",
        "farewell_agent = LlmAgent(\n",
        "    model=MODEL_NAME,\n",
        "    name=AGENT_NAME_FAREWELL,\n",
        "    instruction=\"You are the Farewell Agent. Use the 'say_goodbye' tool when the user indicates they are leaving. Do nothing else.\",\n",
        "    description=\"Handles simple farewells using the 'say_goodbye' tool.\",\n",
        "    tools=[say_goodbye],\n",
        "    disallow_transfer_to_parent=True,\n",
        "    disallow_transfer_to_peers=True,\n",
        ")\n",
        "\n",
        "# --- Define the Parent-Child Relationship ---\n",
        "# This tells the framework how the agents are structured.\n",
        "root_agent.sub_agents = [greeting_agent, farewell_agent]\n",
        "# The framework automatically sets the .parent_agent attribute on the children\n",
        "\n",
        "print(\n",
        "    \"Defined weather_agent (parent), greeting_agent (child), and farewell_agent (child).\"\n",
        ")\n",
        "print(f\"{root_agent.name} children: {[child.name for child in root_agent.sub_agents]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PkWevBdBaK_G"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.sessions import InMemorySessionService\n",
        "import uuid\n",
        "from google.adk.runners import Runner\n",
        "\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "# Required. Unique identifier for the application.\n",
        "APP_NAME = \"weather_app\"\n",
        "# Required. Identifier for the user interacting with the agent. This is a dynamic variable.\n",
        "USER_ID = \"12345\"\n",
        "\n",
        "SESSION_ID = f\"session_{uuid.uuid4()}\"  # Use a dynamic session ID\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "\n",
        "\n",
        "runner = Runner(\n",
        "    agent=root_agent,\n",
        "    app_name=APP_NAME,\n",
        "    session_service=session_service,\n",
        ")\n",
        "\n",
        "\n",
        "def call_agent(user_query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=user_query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrFV75DHaK3G",
        "outputId": "d396c486-668a-46e8-8276-a7d1d3c4ed0f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "call_agent(user_query=\"What's the weather like in Chennai?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIQWRq2qbPMk",
        "outputId": "b48e3fee-aa65-4764-f7b7-91e38e55163f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "call_agent(user_query=\"What about the weather in toronto?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-OvXlb4bYYT",
        "outputId": "db985692-3d37-4ba7-9ca8-78606603d274"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "call_agent(user_query=\"Okay, thanks, bye!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "call_agent(user_query=\"Hi, my friend\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDl005Qnog6j"
      },
      "source": [
        "### LLM Agents with Callbacks (Agent, Model & Tool)\n",
        "\n",
        "- This is useful when you want to inspect the messege exchange agents\n",
        "- This cell shows the available functio parameters that you can use in callback\n",
        "\n",
        "\n",
        "This is how the sequence looks like:\n",
        "- Before Agent Callback > Before Model Callback > After Model Callback > Before Tool Callback > After Tool Callback > Before Model Callback > After Model Callback > After Agent Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wPVFcZ84sfLe"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.agents import LlmAgent\n",
        "import asyncio\n",
        "\n",
        "# Constant\n",
        "APP_NAME = \"weather_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"weather_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "\n",
        "# Tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Retrieves weather information for the given city.\n",
        "\n",
        "    Args:\n",
        "        city: The name of the city for which to retrieve weather information.\n",
        "\n",
        "    Returns:\n",
        "        A string containing the weather information for the specified city,\n",
        "        or a message indicating that the weather information was not found.\n",
        "    \"\"\"\n",
        "    cities = {\n",
        "        \"chicago\": {\"temperature\": 25, \"condition\": \"sunny\", \"sky\": \"clear\"},\n",
        "        \"toronto\": {\"temperature\": 30, \"condition\": \"partly cloudy\", \"sky\": \"overcast\"},\n",
        "        \"chennai\": {\"temperature\": 15, \"condition\": \"rainy\", \"sky\": \"cloudy\"},\n",
        "    }\n",
        "\n",
        "    city_lower = city.lower()\n",
        "    if city_lower in cities:\n",
        "        weather_data = cities[city_lower]\n",
        "        return f\"Weather in {city} is {weather_data['temperature']} degrees Celsius, {weather_data['condition']} with a {weather_data['sky']} sky.\"\n",
        "    else:\n",
        "        return f\"Weather information for {city} not found.\"\n",
        "\n",
        "\n",
        "def get_greeting(name: str) -> str:\n",
        "    \"\"\"Greets the given name.\n",
        "\n",
        "    Args:\n",
        "        name: The name to greet.\n",
        "\n",
        "    Returns:\n",
        "        A greeting message.\n",
        "    \"\"\"\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "\n",
        "# Callbacks\n",
        "\n",
        "\n",
        "def before_model_callback(callback_context, llm_request):\n",
        "    print(\n",
        "        f\"Before Model Callback: Agent {callback_context._invocation_context.agent.name}, Request: {llm_request.contents}\"\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "def after_model_callback(callback_context, llm_response):\n",
        "    print(\n",
        "        f\"After Model Callback: Agent {callback_context._invocation_context.agent.name}, Response: {llm_response.content}\"\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "def before_tool_callback(tool, args, tool_context):\n",
        "    print(f\"Before Tool Callback: Tool {tool.name}, Args: {args}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def after_tool_callback(tool, args, tool_context, tool_response):\n",
        "    print(f\"After Tool Callback: Tool {tool.name}, Response: {tool_response}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def before_agent_callback(callback_context):\n",
        "    print(\n",
        "        f\"Before Agent Callback: Agent {callback_context._invocation_context.agent.name}\"\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "def after_agent_callback(callback_context):\n",
        "    print(\n",
        "        f\"After Agent Callback: Agent {callback_context._invocation_context.agent.name}\"\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "root_agent = LlmAgent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=\"weather_agent\",\n",
        "    instruction=\"\"\"You are a Weather Information Agent. Your task is to provide weather information for a given city.\n",
        "\n",
        "    When a user provides a prompt, extract the city name.\n",
        "    Then, use the `get_weather` tool to retrieve the weather information for that city.\n",
        "    Finally, present the weather information to the user in a clear and concise manner.\n",
        "    If the user asks for a greeting, transfer to the greeting agent.\"\"\",\n",
        "    description=\"\"\"You are an agent who can fetch weather information for a city.\n",
        "    You have access to the `get_weather` tool to accomplish this task.\"\"\",\n",
        "    tools=[get_weather],\n",
        "    before_model_callback=before_model_callback,\n",
        "    after_model_callback=after_model_callback,\n",
        "    before_tool_callback=before_tool_callback,\n",
        "    after_tool_callback=after_tool_callback,\n",
        "    before_agent_callback=before_agent_callback,\n",
        "    after_agent_callback=after_agent_callback,\n",
        ")\n",
        "\n",
        "greeting_agent = LlmAgent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=\"greeting_agent\",\n",
        "    instruction=\"\"\"You are a Greeting Agent. Your task is to greet the user.\n",
        "\n",
        "    When a user provides a prompt, extract the name.\n",
        "    Then, use the `get_greeting` tool to greet the user.\n",
        "    Finally, present the greeting to the user in a clear and concise manner.\n",
        "    If the user asks for weather information, transfer to the weather agent.\"\"\",\n",
        "    description=\"\"\"You are an agent who can greet a user.\n",
        "    You have access to the `get_greeting` tool to accomplish this task.\"\"\",\n",
        "    tools=[get_greeting],\n",
        "    disallow_transfer_to_parent=True,\n",
        "    disallow_transfer_to_peers=True,\n",
        "    before_model_callback=before_model_callback,\n",
        "    after_model_callback=after_model_callback,\n",
        "    before_tool_callback=before_tool_callback,\n",
        "    after_tool_callback=after_tool_callback,\n",
        "    before_agent_callback=before_agent_callback,\n",
        "    after_agent_callback=after_agent_callback,\n",
        ")\n",
        "\n",
        "# Set parent-child relationship\n",
        "root_agent.sub_agents = [greeting_agent]\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "async def call_agent_async(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    async for event in runner.run_async(\n",
        "        user_id=USER_ID, session_id=SESSION_ID, new_message=content\n",
        "    ):\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUPvRHL6k4nx",
        "outputId": "d409e78d-e0e6-4577-ff28-31232b200773"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"What's the weather in Chicago?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLmmHTi3ChKE"
      },
      "source": [
        "### LLM Agent with before_agent_callback and state\n",
        "\n",
        "- In this example, we check the session state `skip_agent`, and decide how the agent will response.\n",
        "- If condition is met, we skip LLM response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2X8Fh4BChmN",
        "outputId": "f7d3487e-96d9-4d73-9d08-a9e2f49ea407"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from typing import AsyncGenerator, Optional\n",
        "from google.adk.agents.invocation_context import InvocationContext\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService, Session\n",
        "from google.adk.events import Event\n",
        "from google.genai import types\n",
        "\n",
        "# Ensure GEMINI_2_FLASH is defined (replace if needed)\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"  # Or your preferred model\n",
        "\n",
        "\n",
        "# --- Define the Callback Function (Same as before) ---\n",
        "def simple_before_agent_logger(\n",
        "    callback_context: CallbackContext,\n",
        ") -> Optional[types.Content]:\n",
        "    \"\"\"Logs entry into an agent and checks a condition.\"\"\"\n",
        "    agent_name = callback_context.agent_name\n",
        "    invocation_id = callback_context.invocation_id\n",
        "    print(f\"[Callback] Entering agent: {agent_name} (Invocation: {invocation_id})\")\n",
        "\n",
        "    # Example: Check a condition in state\n",
        "    if callback_context.state.get(\"skip_agent\", False):\n",
        "        print(f\"[Callback] Condition met: Skipping agent {agent_name}.\")\n",
        "        # Return Content to skip the agent's run\n",
        "        return types.Content(\n",
        "            parts=[types.Part(text=f\"Agent {agent_name} was skipped by callback.\")]\n",
        "        )\n",
        "    else:\n",
        "        print(f\"[Callback] Condition not met: Proceeding with agent {agent_name}.\")\n",
        "        # Return None to allow the agent's run to execute\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- Setup and Run ---\n",
        "async def main():\n",
        "    # 1. Create LlmAgent and Assign Callback\n",
        "    my_llm_agent = LlmAgent(\n",
        "        name=\"SimpleLlmAgent\",\n",
        "        model=GEMINI_2_FLASH,\n",
        "        instruction=\"You are a simple agent. Just say 'Hello!'\",\n",
        "        description=\"An LLM agent demonstrating before_agent_callback\",\n",
        "        before_agent_callback=simple_before_agent_logger,\n",
        "    )\n",
        "\n",
        "    # 2. Setup Runner and Session\n",
        "    session_service = InMemorySessionService()\n",
        "    runner = Runner(\n",
        "        agent=my_llm_agent, app_name=\"llm_demo_app\", session_service=session_service\n",
        "    )\n",
        "    session_id_run = \"llm_session_run_1\"\n",
        "    session_id_skip = \"llm_session_skip_1\"\n",
        "    user_id = \"llm_test_user\"\n",
        "\n",
        "    # Create sessions\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_demo_app\", user_id=user_id, session_id=session_id_run\n",
        "    )\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_demo_app\",\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_skip,\n",
        "        state={\"skip_agent\": True},\n",
        "    )  # Set state to trigger skip condition\n",
        "\n",
        "    print(\"--- Running LLM Agent Normally ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_run,\n",
        "        new_message=types.Content(role=\"user\", parts=[types.Part(text=\"Run normally\")]),\n",
        "    ):\n",
        "        # Only print final LLM response or callback override\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )  # Added strip() for cleaner output\n",
        "\n",
        "    print(\"\\n--- Running LLM Agent with Skip Condition ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_skip,\n",
        "        new_message=types.Content(parts=[types.Part(text=\"Skip this agent\")]),\n",
        "    ):\n",
        "        # Only print final LLM response or callback override\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhpRxvkuFoIt"
      },
      "source": [
        "### LLM Agent with after_agent_callback and state\n",
        "\n",
        "- In this use case, we check the `add_concluding_note` session state.\n",
        "- If condition is met, we append extra message to LLM response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2hWWDwNFodQ",
        "outputId": "e766ace8-bb30-40a8-f2f4-2215f38c771b"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from typing import AsyncGenerator, Optional\n",
        "from google.adk.agents.invocation_context import InvocationContext\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService, Session\n",
        "from google.adk.events import Event\n",
        "from google.genai import types\n",
        "\n",
        "# Ensure GEMINI_2_FLASH is defined (replace if needed)\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"  # Or your preferred model\n",
        "\n",
        "\n",
        "# --- Define the Callback Function ---\n",
        "def simple_after_agent_logger(\n",
        "    callback_context: CallbackContext,\n",
        ") -> Optional[types.Content]:\n",
        "    \"\"\"Logs exit from an agent and optionally appends a message.\"\"\"\n",
        "    agent_name = callback_context.agent_name\n",
        "    invocation_id = callback_context.invocation_id\n",
        "    print(f\"[Callback] Exiting agent: {agent_name} (Invocation: {invocation_id})\")\n",
        "\n",
        "    # Example: Optionally return Content to append a message\n",
        "    if callback_context.state.get(\"add_concluding_note\", False):\n",
        "        print(f\"[Callback] Adding concluding note for agent {agent_name}.\")\n",
        "        # Return Content to append after the agent's own output\n",
        "        return types.Content(\n",
        "            parts=[types.Part(text=f\"Concluding note added by after_agent_callback.\")]\n",
        "        )\n",
        "    else:\n",
        "        print(f\"[Callback] No concluding note added for agent {agent_name}.\")\n",
        "        # Return None - no additional message appended\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- Setup and Run ---\n",
        "async def main():\n",
        "    # 1. Create LlmAgent and Assign Callback\n",
        "    my_llm_agent = LlmAgent(\n",
        "        name=\"SimpleLlmAgentWithAfter\",\n",
        "        model=GEMINI_2_FLASH,\n",
        "        instruction=\"You are a simple agent. Just say 'Processing complete!'\",\n",
        "        description=\"An LLM agent demonstrating after_agent_callback\",\n",
        "        after_agent_callback=simple_after_agent_logger,  # Assign the function here\n",
        "    )\n",
        "\n",
        "    # 2. Setup Runner and Session\n",
        "    session_service = InMemorySessionService()\n",
        "    runner = Runner(\n",
        "        agent=my_llm_agent,\n",
        "        app_name=\"llm_demo_app_after\",\n",
        "        session_service=session_service,\n",
        "    )\n",
        "    session_id_run = \"llm_session_run_after_1\"\n",
        "    session_id_conclude = \"llm_session_conclude_1\"\n",
        "    user_id = \"llm_test_user_after\"\n",
        "\n",
        "    # Create sessions\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_demo_app_after\", user_id=user_id, session_id=session_id_run\n",
        "    )\n",
        "    # Session where the callback will add a note\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_demo_app_after\",\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_conclude,\n",
        "        state={\"add_concluding_note\": True},\n",
        "    )\n",
        "\n",
        "    # Test with different session_id\n",
        "    print(\"--- Running LLM Agent Normally (with after_agent_callback) ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_run,\n",
        "        new_message=types.Content(role=\"user\", parts=[types.Part(text=\"Run normally\")]),\n",
        "    ):\n",
        "        # Print any event content from agent or callback\n",
        "        if event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "    print(\"\\n--- Running LLM Agent with Concluding Note Condition ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_conclude,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\", parts=[types.Part(text=\"Run and conclude\")]\n",
        "        ),\n",
        "    ):\n",
        "        # Print any event content from agent or callback\n",
        "        if event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGs43srmLq7y"
      },
      "source": [
        "### LLM Agent with before_model_callback and state\n",
        "\n",
        "In this example, we demonstrate how to\n",
        "\n",
        "- modify system instruction\n",
        "- block model response based on keyword in query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCxIFM8CLrNx",
        "outputId": "a277150a-8394-4eb9-f2d1-16729331f7c3"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from typing import AsyncGenerator, Optional\n",
        "from google.adk.agents.invocation_context import InvocationContext\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "\n",
        "# Need LlmRequest and LlmResponse for the callback signature and return type\n",
        "from google.adk.models.llm_request import LlmRequest\n",
        "from google.adk.models.llm_response import LlmResponse\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService, Session\n",
        "from google.adk.events import Event\n",
        "from google.genai import types\n",
        "\n",
        "# Ensure GEMINI_2_FLASH is defined (replace if needed)\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"  # Or your preferred model\n",
        "\n",
        "\n",
        "# --- Define the Callback Function ---\n",
        "def simple_before_model_modifier(\n",
        "    callback_context: CallbackContext, llm_request: LlmRequest\n",
        ") -> Optional[LlmResponse]:\n",
        "    \"\"\"Inspects/modifies the LLM request or skips the call.\"\"\"\n",
        "    agent_name = callback_context.agent_name\n",
        "    print(f\"[Callback] Before model call for agent: {agent_name}\")\n",
        "\n",
        "    # Inspect the last user message in the request contents\n",
        "    last_user_message = \"\"\n",
        "    if llm_request.contents and llm_request.contents[-1].role == \"user\":\n",
        "        if llm_request.contents[-1].parts:\n",
        "            last_user_message = llm_request.contents[-1].parts[0].text\n",
        "    print(f\"[Callback] Inspecting last user message: '{last_user_message}'\")\n",
        "\n",
        "    # --- Modification Example ---\n",
        "    # Add a prefix to the system instruction\n",
        "    original_instruction = llm_request.config.system_instruction or types.Content(\n",
        "        role=\"system\", parts=[]\n",
        "    )\n",
        "    prefix = \"[Modified by Callback] \"\n",
        "    # Ensure system_instruction is Content and parts list exists\n",
        "    if not isinstance(original_instruction, types.Content):\n",
        "        # Handle case where it might be a string (though config expects Content)\n",
        "        original_instruction = types.Content(\n",
        "            role=\"system\", parts=[types.Part(text=str(original_instruction))]\n",
        "        )\n",
        "    if not original_instruction.parts:\n",
        "        original_instruction.parts.append(\n",
        "            types.Part(text=\"\")\n",
        "        )  # Add an empty part if none exist\n",
        "\n",
        "    # Modify the text of the first part\n",
        "    modified_text = prefix + (original_instruction.parts[0].text or \"\")\n",
        "    original_instruction.parts[0].text = modified_text\n",
        "    llm_request.config.system_instruction = original_instruction\n",
        "    print(f\"[Callback] Modified system instruction to: '{modified_text}'\")\n",
        "\n",
        "    # --- Skip Example ---\n",
        "    # Check if the last user message contains \"BLOCK\"\n",
        "    if \"BLOCK\" in last_user_message.upper():\n",
        "        print(\"[Callback] 'BLOCK' keyword found. Skipping LLM call.\")\n",
        "        # Return an LlmResponse to skip the actual LLM call\n",
        "        return LlmResponse(\n",
        "            content=types.Content(\n",
        "                role=\"model\",\n",
        "                parts=[\n",
        "                    types.Part(text=\"LLM call was blocked by before_model_callback.\")\n",
        "                ],\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        print(\"[Callback] Proceeding with LLM call.\")\n",
        "        # Return None to allow the (modified) request to go to the LLM\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- Setup and Run ---\n",
        "async def main():\n",
        "    # 1. Create LlmAgent and Assign Callback\n",
        "    my_llm_agent = LlmAgent(\n",
        "        name=\"ModelCallbackAgent\",\n",
        "        model=GEMINI_2_FLASH,\n",
        "        instruction=\"You are a helpful assistant.\",  # Base instruction\n",
        "        description=\"An LLM agent demonstrating before_model_callback\",\n",
        "        before_model_callback=simple_before_model_modifier,  # Assign the function here\n",
        "    )\n",
        "\n",
        "    # 2. Setup Runner and Session\n",
        "    session_service = InMemorySessionService()\n",
        "    runner = Runner(\n",
        "        agent=my_llm_agent, app_name=\"llm_model_cb_app\", session_service=session_service\n",
        "    )\n",
        "    session_id_run = \"model_cb_run_1\"\n",
        "    session_id_block = \"model_cb_block_1\"\n",
        "    user_id = \"model_cb_user\"\n",
        "\n",
        "    # Create sessions\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_model_cb_app\", user_id=user_id, session_id=session_id_run\n",
        "    )\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_model_cb_app\", user_id=user_id, session_id=session_id_block\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        \"--- Running LLM Agent Normally (with before_model_callback modification) ---\"\n",
        "    )\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_run,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\", parts=[types.Part(text=\"Tell me a short joke.\")]\n",
        "        ),\n",
        "    ):\n",
        "        # Only print final LLM response or callback override\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "    print(\"\\n--- Running LLM Agent with BLOCK Keyword (triggering skip) ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_block,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\", parts=[types.Part(text=\"BLOCK this request.\")]\n",
        "        ),\n",
        "    ):\n",
        "        # Only print final LLM response or callback override\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qhO2G_wLrgl"
      },
      "source": [
        "### LLM Agent with after_model_callback and state\n",
        "\n",
        "This use case demonstract\n",
        "- overwriting model response with custom text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n38CnCEfLrw_",
        "outputId": "c17c46d0-06ea-4d12-8153-899eab7bbe6f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from typing import AsyncGenerator, Optional\n",
        "import copy  # Needed to safely modify response content\n",
        "\n",
        "from google.adk.agents.invocation_context import InvocationContext\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.adk.models.llm_request import LlmRequest\n",
        "from google.adk.models.llm_response import LlmResponse\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService, Session\n",
        "from google.adk.events import Event\n",
        "from google.genai import types\n",
        "\n",
        "# Ensure GEMINI_2_FLASH is defined (replace if needed)\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"  # Or your preferred model\n",
        "\n",
        "\n",
        "# --- Define the Callback Function ---\n",
        "def simple_after_model_modifier(\n",
        "    callback_context: CallbackContext, llm_response: LlmResponse\n",
        ") -> Optional[LlmResponse]:\n",
        "    \"\"\"Inspects/modifies the LLM response after it's received.\"\"\"\n",
        "    agent_name = callback_context.agent_name\n",
        "    print(f\"[Callback] After model call for agent: {agent_name}\")\n",
        "\n",
        "    # --- Inspection ---\n",
        "    original_text = \"\"\n",
        "    if llm_response.content and llm_response.content.parts:\n",
        "        # Assuming simple text response for this example\n",
        "        if llm_response.content.parts[0].text:\n",
        "            original_text = llm_response.content.parts[0].text\n",
        "            print(\n",
        "                f\"[Callback] Inspected original response text: '{original_text[:100]}...'\"\n",
        "            )  # Log snippet\n",
        "        elif llm_response.content.parts[0].function_call:\n",
        "            print(\n",
        "                f\"[Callback] Inspected response: Contains function call '{llm_response.content.parts[0].function_call.name}'. No text modification.\"\n",
        "            )\n",
        "            return None  # Don't modify tool calls in this example\n",
        "        else:\n",
        "            print(\"[Callback] Inspected response: No text content found.\")\n",
        "            return None\n",
        "    elif llm_response.error_message:\n",
        "        print(\n",
        "            f\"[Callback] Inspected response: Contains error '{llm_response.error_message}'. No modification.\"\n",
        "        )\n",
        "        return None\n",
        "    else:\n",
        "        print(\"[Callback] Inspected response: Empty LlmResponse.\")\n",
        "        return None  # Nothing to modify\n",
        "\n",
        "    # --- Modification Example ---\n",
        "    # Replace \"scientists\" with \"funny scientists\" (case-insensitive)\n",
        "    search_term = \"scientists\"\n",
        "    replace_term = \"CUSTOM scientists\"\n",
        "    if search_term in original_text.lower():\n",
        "        print(f\"[Callback] Found '{search_term}'. Modifying response.\")\n",
        "        modified_text = original_text.replace(search_term, replace_term)\n",
        "        modified_text = modified_text.replace(\n",
        "            search_term.capitalize(), replace_term.capitalize()\n",
        "        )  # Handle capitalization\n",
        "\n",
        "        # Create a NEW LlmResponse with the modified content\n",
        "        # Deep copy parts to avoid modifying original if other callbacks exist\n",
        "        modified_parts = [copy.deepcopy(part) for part in llm_response.content.parts]\n",
        "        modified_parts[0].text = modified_text  # Update the text in the copied part\n",
        "\n",
        "        new_response = LlmResponse(\n",
        "            content=types.Content(role=\"model\", parts=modified_parts),\n",
        "            # Copy other relevant fields if necessary, e.g., grounding_metadata\n",
        "            grounding_metadata=llm_response.grounding_metadata,\n",
        "        )\n",
        "        print(f\"[Callback] Returning modified response.\")\n",
        "        return new_response  # Return the modified response\n",
        "    else:\n",
        "        print(\n",
        "            f\"[Callback] '{search_term}' not found. Passing original response through.\"\n",
        "        )\n",
        "        # Return None to use the original llm_response\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- Setup and Run ---\n",
        "async def main():\n",
        "    # 1. Create LlmAgent and Assign Callback\n",
        "    my_llm_agent = LlmAgent(\n",
        "        name=\"AfterModelCallbackAgent\",\n",
        "        model=GEMINI_2_FLASH,\n",
        "        instruction=\"You are a helpful assistant.\",\n",
        "        description=\"An LLM agent demonstrating after_model_callback\",\n",
        "        after_model_callback=simple_after_model_modifier,  # Assign the function here\n",
        "    )\n",
        "\n",
        "    # 2. Setup Runner and Session\n",
        "    session_service = InMemorySessionService()\n",
        "    runner = Runner(\n",
        "        agent=my_llm_agent,\n",
        "        app_name=\"llm_after_model_cb_app\",\n",
        "        session_service=session_service,\n",
        "    )\n",
        "    session_id_run = \"after_model_cb_run_1\"\n",
        "    session_id_modify = \"after_model_cb_modify_1\"\n",
        "    user_id = \"after_model_cb_user\"\n",
        "\n",
        "    # Create sessions\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_after_model_cb_app\", user_id=user_id, session_id=session_id_run\n",
        "    )\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_after_model_cb_app\", user_id=user_id, session_id=session_id_modify\n",
        "    )\n",
        "\n",
        "    print(\"--- Running LLM Agent Normally (Callback passes response through) ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_run,\n",
        "        new_message=types.Content(role=\"user\", parts=[types.Part(text=\"Say hello.\")]),\n",
        "    ):\n",
        "        # Only print final LLM response\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "    print(\"\\n--- Running LLM Agent with Input Triggering Modification ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_modify,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\", parts=[types.Part(text=\"Why don't scientists trust atoms\")]\n",
        "        ),\n",
        "    ):\n",
        "        # Only print final LLM response\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNdkfIVGQ3Af"
      },
      "source": [
        "### LLM Agent with before_tool_callback and state\n",
        "\n",
        "This cell demonstract:\n",
        "- inspection of tool arguments, and overwriting of argument and response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zsGbxXwQ3Po",
        "outputId": "0b14f3a7-0107-42ed-c5db-3b45e8d91d7f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from typing import AsyncGenerator, Optional, Dict, Any\n",
        "import copy\n",
        "\n",
        "from google.adk.agents.invocation_context import InvocationContext\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "\n",
        "# Need LlmRequest, LlmResponse for context\n",
        "from google.adk.models.llm_request import LlmRequest\n",
        "from google.adk.models.llm_response import LlmResponse\n",
        "\n",
        "# Need BaseTool, ToolContext for the callback signature\n",
        "from google.adk.tools.base_tool import BaseTool\n",
        "from google.adk.tools.tool_context import ToolContext\n",
        "\n",
        "# Using FunctionTool to easily create a tool\n",
        "from google.adk.tools.function_tool import FunctionTool\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService, Session\n",
        "from google.adk.events import Event\n",
        "from google.genai import types\n",
        "\n",
        "# Ensure GEMINI_2_FLASH is defined (replace if needed)\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"  # Or your preferred model\n",
        "\n",
        "\n",
        "# --- Define a Simple Tool Function ---\n",
        "def get_capital_city(country: str) -> str:\n",
        "    \"\"\"Retrieves the capital city of a given country.\"\"\"\n",
        "    print(f\"--- Tool 'get_capital_city' executing with country: {country} ---\")\n",
        "    country_capitals = {\n",
        "        \"united states\": \"Washington, D.C.\",\n",
        "        \"canada\": \"Ottawa\",  # Intentionally correct here\n",
        "        \"france\": \"Paris\",\n",
        "        \"germany\": \"Berlin\",\n",
        "    }\n",
        "    return country_capitals.get(country.lower(), f\"Capital not found for {country}\")\n",
        "\n",
        "\n",
        "# --- Wrap the function into a Tool ---\n",
        "capital_tool = FunctionTool(func=get_capital_city)\n",
        "\n",
        "\n",
        "# --- Define the Callback Function ---\n",
        "def simple_before_tool_modifier(\n",
        "    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext\n",
        ") -> Optional[Dict]:\n",
        "    \"\"\"Inspects/modifies tool args or skips the tool call.\"\"\"\n",
        "    agent_name = tool_context.agent_name\n",
        "    tool_name = tool.name\n",
        "    print(f\"[Callback] Before tool call for tool '{tool_name}' in agent '{agent_name}'\")\n",
        "    print(f\"[Callback] Original args: {args}\")\n",
        "\n",
        "    # --- Modification Example ---\n",
        "    # If the tool is 'get_capital_city' and country is 'Canada', change it to 'France'\n",
        "    if tool_name == \"get_capital_city\" and args.get(\"country\", \"\").lower() == \"canada\":\n",
        "        print(\"[Callback] Detected 'Canada'. Modifying args to 'France'.\")\n",
        "        args[\"country\"] = \"France\"  # Modify the args dictionary directly\n",
        "        print(f\"[Callback] Modified args: {args}\")\n",
        "        return None  # Proceed with modified args\n",
        "\n",
        "    # --- Skip Example ---\n",
        "    # If the tool is 'get_capital_city' and country is 'BLOCK'\n",
        "    if tool_name == \"get_capital_city\" and args.get(\"country\", \"\").upper() == \"BLOCK\":\n",
        "        print(\"[Callback] Detected 'BLOCK'. Skipping tool execution.\")\n",
        "        # Return a dictionary to be used as the tool result, skipping the actual tool call\n",
        "        return {\"result\": \"Tool execution was blocked by before_tool_callback.\"}\n",
        "\n",
        "    print(\"[Callback] Proceeding with original or previously modified args.\")\n",
        "    # Return None to allow the tool to execute normally (with original or modified args)\n",
        "    return None\n",
        "\n",
        "\n",
        "# --- Setup and Run ---\n",
        "async def main():\n",
        "    # 1. Create LlmAgent with the tool and callback\n",
        "    my_llm_agent = LlmAgent(\n",
        "        name=\"ToolCallbackAgent\",\n",
        "        model=GEMINI_2_FLASH,\n",
        "        instruction=\"You are an agent that can find capital cities. Use the get_capital_city tool.\",\n",
        "        description=\"An LLM agent demonstrating before_tool_callback\",\n",
        "        tools=[capital_tool],  # Add the tool here\n",
        "        before_tool_callback=simple_before_tool_modifier,  # Assign the callback here\n",
        "    )\n",
        "\n",
        "    # 2. Setup Runner and Session\n",
        "    session_service = InMemorySessionService()\n",
        "    runner = Runner(\n",
        "        agent=my_llm_agent, app_name=\"llm_tool_cb_app\", session_service=session_service\n",
        "    )\n",
        "    session_id_run = \"tool_cb_run_1\"\n",
        "    session_id_modify = \"tool_cb_modify_1\"\n",
        "    session_id_block = \"tool_cb_block_1\"\n",
        "    user_id = \"tool_cb_user\"\n",
        "\n",
        "    # Create sessions\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_tool_cb_app\", user_id=user_id, session_id=session_id_run\n",
        "    )\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_tool_cb_app\", user_id=user_id, session_id=session_id_modify\n",
        "    )\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_tool_cb_app\", user_id=user_id, session_id=session_id_block\n",
        "    )\n",
        "\n",
        "    print(\"--- Running Agent (Normal Tool Call - Germany) ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_run,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\", parts=[types.Part(text=\"What is the capital of Germany?\")]\n",
        "        ),\n",
        "    ):\n",
        "        # Only print final LLM response\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "    print(\n",
        "        \"\\n--- Running Agent (Tool Call Triggering Modification - Canada -> France) ---\"\n",
        "    )\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_modify,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\", parts=[types.Part(text=\"What is the capital of Canada?\")]\n",
        "        ),\n",
        "    ):\n",
        "        # Only print final LLM response\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "    print(\"\\n--- Running Agent (Tool Call Triggering Skip - BLOCK) ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_block,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\", parts=[types.Part(text=\"What is the capital of BLOCK?\")]\n",
        "        ),\n",
        "    ):\n",
        "        # Only print final LLM response\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-36dSreYQ3mG"
      },
      "source": [
        "### LLM Agent with after_tool_callback and state\n",
        "\n",
        "- Modify tool call result based on tool argument.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEFUbgV3Q352",
        "outputId": "58bb6039-c6d4-4023-e626-7f4cd5de808f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from typing import AsyncGenerator, Optional, Dict, Any\n",
        "import copy  # Good practice for modifying results\n",
        "\n",
        "from google.adk.agents.invocation_context import InvocationContext\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.adk.models.llm_request import LlmRequest\n",
        "from google.adk.models.llm_response import LlmResponse\n",
        "from google.adk.tools.base_tool import BaseTool\n",
        "from google.adk.tools.tool_context import ToolContext\n",
        "from google.adk.tools.function_tool import FunctionTool\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService, Session\n",
        "from google.adk.events import Event\n",
        "from google.genai import types\n",
        "\n",
        "# Ensure GEMINI_2_FLASH is defined (replace if needed)\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"  # Or your preferred model\n",
        "\n",
        "\n",
        "# --- Define a Simple Tool Function (Same as before) ---\n",
        "def get_capital_city(country: str) -> str:\n",
        "    \"\"\"Retrieves the capital city of a given country.\"\"\"\n",
        "    print(f\"--- Tool 'get_capital_city' executing with country: {country} ---\")\n",
        "    country_capitals = {\n",
        "        \"united states\": \"Washington, D.C.\",\n",
        "        \"canada\": \"Ottawa\",\n",
        "        \"france\": \"Paris\",\n",
        "        \"germany\": \"Berlin\",\n",
        "    }\n",
        "    return {\n",
        "        \"result\": country_capitals.get(\n",
        "            country.lower(), f\"Capital not found for {country}\"\n",
        "        )\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Wrap the function into a Tool ---\n",
        "capital_tool = FunctionTool(func=get_capital_city)\n",
        "\n",
        "\n",
        "# --- Define the Callback Function ---\n",
        "def simple_after_tool_modifier(\n",
        "    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext, tool_response: Dict\n",
        ") -> Optional[Dict]:\n",
        "    \"\"\"Inspects/modifies the tool result after execution.\"\"\"\n",
        "    agent_name = tool_context.agent_name\n",
        "    tool_name = tool.name\n",
        "    print(f\"[Callback] After tool call for tool '{tool_name}' in agent '{agent_name}'\")\n",
        "    print(f\"[Callback] Args used: {args}\")\n",
        "    print(f\"[Callback] Original tool_response: {tool_response}\")\n",
        "\n",
        "    # Default structure for function tool results is {\"result\": <return_value>}\n",
        "    original_result_value = tool_response.get(\"result\", \"\")\n",
        "    # original_result_value = tool_response\n",
        "\n",
        "    # --- Modification Example ---\n",
        "    # If the tool was 'get_capital_city' and result is 'Washington, D.C.'\n",
        "    if tool_name == \"get_capital_city\" and original_result_value == \"Washington, D.C.\":\n",
        "        print(\"[Callback] Detected 'Washington, D.C.'. Modifying tool response.\")\n",
        "\n",
        "        # IMPORTANT: Create a new dictionary or modify a copy\n",
        "        modified_response = copy.deepcopy(tool_response)\n",
        "        modified_response[\"result\"] = (\n",
        "            f\"{original_result_value} (Note: This is the capital of the USA).\"\n",
        "        )\n",
        "        modified_response[\"note_added_by_callback\"] = True  # Add extra info if needed\n",
        "\n",
        "        print(f\"[Callback] Modified tool_response: {modified_response}\")\n",
        "        return modified_response  # Return the modified dictionary\n",
        "\n",
        "    print(\"[Callback] Passing original tool response through.\")\n",
        "    # Return None to use the original tool_response\n",
        "    return None\n",
        "\n",
        "\n",
        "# --- Setup and Run ---\n",
        "async def main():\n",
        "    # 1. Create LlmAgent with the tool and callback\n",
        "    my_llm_agent = LlmAgent(\n",
        "        name=\"AfterToolCallbackAgent\",\n",
        "        model=GEMINI_2_FLASH,\n",
        "        instruction=\"You are an agent that finds capital cities using the get_capital_city tool. Report the result clearly.\",\n",
        "        description=\"An LLM agent demonstrating after_tool_callback\",\n",
        "        tools=[capital_tool],  # Add the tool\n",
        "        after_tool_callback=simple_after_tool_modifier,  # Assign the callback\n",
        "    )\n",
        "\n",
        "    # 2. Setup Runner and Session\n",
        "    session_service = InMemorySessionService()\n",
        "    runner = Runner(\n",
        "        agent=my_llm_agent,\n",
        "        app_name=\"llm_after_tool_cb_app\",\n",
        "        session_service=session_service,\n",
        "    )\n",
        "    session_id_run = \"after_tool_cb_run_1\"\n",
        "    session_id_modify = \"after_tool_cb_modify_1\"\n",
        "    user_id = \"after_tool_cb_user\"\n",
        "\n",
        "    # Create sessions\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_after_tool_cb_app\", user_id=user_id, session_id=session_id_run\n",
        "    )\n",
        "    session_service.create_session(\n",
        "        app_name=\"llm_after_tool_cb_app\", user_id=user_id, session_id=session_id_modify\n",
        "    )\n",
        "\n",
        "    print(\"--- Running Agent (Callback passes result through - France) ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_run,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\", parts=[types.Part(text=\"What is the capital of France?\")]\n",
        "        ),\n",
        "    ):\n",
        "        # Only print final LLM response\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "    print(\"\\n--- Running Agent (Callback modifies result - United States) ---\")\n",
        "    async for event in runner.run_async(\n",
        "        user_id=user_id,\n",
        "        session_id=session_id_modify,\n",
        "        new_message=types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[types.Part(text=\"What is the capital of the United States?\")],\n",
        "        ),\n",
        "    ):\n",
        "        # Only print final LLM response\n",
        "        if event.is_final_response() and event.content:\n",
        "            print(\n",
        "                f\"Event Output: {event.author}: {event.content.parts[0].text.strip()}\"\n",
        "            )\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yecR7byQ01bQ"
      },
      "source": [
        "### LLM Agent with Gaurdrail (Profanity Checker with before_model callback)\n",
        "\n",
        "- Prevent model calling if there is bad word detected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xexSYqxPuSiH"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.adk.agents.llm_agent import AfterModelCallback, BeforeModelCallback\n",
        "from google.adk.models.llm_request import LlmRequest\n",
        "from google.adk.models.llm_response import LlmResponse\n",
        "from google.adk.agents.llm_agent import LlmAgent\n",
        "from typing import Any, List, Optional\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.agents import LlmAgent\n",
        "\n",
        "\n",
        "def profanity_guardrail(\n",
        "    callback_context: CallbackContext, llm_request: LlmRequest\n",
        ") -> Optional[LlmResponse]:\n",
        "    \"\"\"Check for profanity in the model request.\"\"\"\n",
        "    profanity_list: List[str] = [\"badword1\", \"badword2\", \"badword3\"]\n",
        "    if llm_request.contents:\n",
        "        for content in llm_request.contents:\n",
        "            for part in content.parts:\n",
        "                if part.text:\n",
        "                    for profanity in profanity_list:\n",
        "                        if profanity in part.text.lower():\n",
        "                            callback_context.state[\"profanity_trigger\"] = True\n",
        "                            return LlmResponse(\n",
        "                                content=types.Content(\n",
        "                                    role=\"model\",\n",
        "                                    parts=[types.Part(text=(\"No bad word allowed.\"))],\n",
        "                                )\n",
        "                            )\n",
        "    return None\n",
        "\n",
        "\n",
        "# Tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Retrieves weather information for the given city.\n",
        "\n",
        "    Args:\n",
        "        city: The name of the city for which to retrieve weather information.\n",
        "\n",
        "    Returns:\n",
        "        A string containing the weather information for the specified city,\n",
        "        or a message indicating that the weather information was not found.\n",
        "    \"\"\"\n",
        "    cities = {\n",
        "        \"chicago\": {\"temperature\": 25, \"condition\": \"sunny\", \"sky\": \"clear\"},\n",
        "        \"toronto\": {\"temperature\": 30, \"condition\": \"partly cloudy\", \"sky\": \"overcast\"},\n",
        "        \"chennai\": {\"temperature\": 15, \"condition\": \"rainy\", \"sky\": \"cloudy\"},\n",
        "    }\n",
        "\n",
        "    city_lower = city.lower()\n",
        "    if city_lower in cities:\n",
        "        weather_data = cities[city_lower]\n",
        "        return f\"Weather in {city} is {weather_data['temperature']} degrees Celsius, {weather_data['condition']} with a {weather_data['sky']} sky.\"\n",
        "    else:\n",
        "        return f\"Weather information for {city} not found.\"\n",
        "\n",
        "\n",
        "async def run_query(query: str):\n",
        "    weather_agent = LlmAgent(\n",
        "        model=GEMINI_2_FLASH,\n",
        "        name=\"weather_agent\",\n",
        "        instruction=\"\"\"You are a Weather Information Agent. Your task is to provide weather information for a given city.\n",
        "\n",
        "        When a user provides a prompt, extract the city name.\n",
        "        Then, use the `get_weather` tool to retrieve the weather information for that city.\n",
        "        Finally, present the weather information to the user in a clear and concise manner.\n",
        "        If the user asks for a greeting, transfer to the greeting agent.\"\"\",\n",
        "        description=\"\"\"You are an agent who can fetch weather information for a city.\n",
        "        You have access to the `get_weather` tool to accomplish this task.\"\"\",\n",
        "        tools=[get_weather],\n",
        "        before_model_callback=profanity_guardrail,\n",
        "    )\n",
        "\n",
        "    session_service = InMemorySessionService()\n",
        "    session = session_service.create_session(\n",
        "        app_name=\"weather_app\", user_id=\"12345\", session_id=\"123344\"\n",
        "    )\n",
        "    runner = Runner(\n",
        "        agent=weather_agent,\n",
        "        app_name=\"weather_app\",\n",
        "        session_service=session_service,\n",
        "    )\n",
        "\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    async for event in runner.run_async(\n",
        "        user_id=\"12345\", session_id=\"123344\", new_message=content\n",
        "    ):\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(f\"Query: {query}\")\n",
        "            print(f\"Agent Response: {final_response}\")\n",
        "            print(\"-\" * 20)\n",
        "        if \"profanity_trigger\" in event.actions.state_delta:\n",
        "            print(\n",
        "                f\"Profanity Triggered: {event.actions.state_delta['profanity_trigger']}\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K2D004BzaEv",
        "outputId": "b2b789fb-166c-4392-9721-9b4ec7156e14"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "await run_query(\"What is the weather in Chicago?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3L1N4AXza-C",
        "outputId": "4efaf126-23e5-43ea-ec15-8d5173a586a5"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "await run_query(\"what the badword1 is the weather in Chicago?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG4lwya4iUoX"
      },
      "source": [
        "### LlmAgent with All Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a89KSH0tiUb1",
        "outputId": "f6159277-4327-47fe-f8e5-3472906376f1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import warnings\n",
        "import os\n",
        "from typing import Any, Optional, Dict, List, AsyncGenerator\n",
        "\n",
        "# --- ADK Imports ---\n",
        "from google.adk.agents import Agent, LlmAgent, BaseAgent  # Using LlmAgent directly\n",
        "from google.adk.sessions import InMemorySessionService, Session, State\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.models.llm_request import LlmRequest\n",
        "from google.adk.models.llm_response import LlmResponse\n",
        "from google.adk.tools.base_tool import BaseTool\n",
        "from google.adk.tools.tool_context import ToolContext\n",
        "from google.adk.tools.function_tool import FunctionTool\n",
        "from google.adk.events import Event\n",
        "from google.adk.agents.invocation_context import InvocationContext\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.genai import types\n",
        "\n",
        "# Suppress specific UserWarning from google.generativeai if necessary\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\", category=UserWarning, module=\"google.generativeai.types.content_types\"\n",
        ")\n",
        "\n",
        "# --- Constants ---\n",
        "APP_NAME = \"support_ticket_app\"\n",
        "USER_ID = \"customer_123\"\n",
        "SESSION_ID = \"ticket_session_abc\"\n",
        "AGENT_NAME = \"support_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"  # Or your preferred Gemini model\n",
        "\n",
        "\n",
        "# --- Simulated Knowledge Base Tool ---\n",
        "def kb_search(keywords: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Searches the knowledge base for troubleshooting steps based on keywords.\n",
        "\n",
        "    Args:\n",
        "        keywords: A list of keywords related to the issue (e.g., ['screen', 'flickering']).\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing potential solutions or an empty dictionary if none found.\n",
        "    \"\"\"\n",
        "    print(f\"      [Tool Executing: kb_search with keywords: {keywords}]\")\n",
        "    # Simple mock implementation\n",
        "    mock_kb = {\n",
        "        \"screen\": [\n",
        "            \"Check the display cable connection.\",\n",
        "            \"Try a different monitor port.\",\n",
        "        ],\n",
        "        \"flickering\": [\n",
        "            \"Update the graphics driver.\",\n",
        "            \"Adjust the screen refresh rate.\",\n",
        "        ],\n",
        "        \"display\": [\"Ensure monitor power is on.\", \"Reboot the computer.\"],\n",
        "        \"keyboard\": [\"Check battery if wireless.\", \"Try a different USB port.\"],\n",
        "    }\n",
        "    results = []\n",
        "    for keyword in keywords:\n",
        "        if keyword.lower() in mock_kb:\n",
        "            results.extend(mock_kb[keyword.lower()])\n",
        "\n",
        "    if results:\n",
        "        # Remove duplicates while preserving order (if Python 3.7+)\n",
        "        unique_results = list(dict.fromkeys(results))\n",
        "        print(f\"      [Tool Result: Found {len(unique_results)} steps]\")\n",
        "        return {\"solutions\": unique_results}\n",
        "    else:\n",
        "        print(\"      [Tool Result: No relevant KB articles found]\")\n",
        "        return {\n",
        "            \"solutions\": [\n",
        "                \"No specific troubleshooting steps found in KB for these keywords.\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "\n",
        "# Wrap the function into a FunctionTool\n",
        "kb_search_tool = FunctionTool(func=kb_search)\n",
        "\n",
        "\n",
        "# --- Callback Implementations ---\n",
        "\n",
        "\n",
        "def log_before_agent(callback_context: CallbackContext) -> Optional[types.Content]:\n",
        "    \"\"\"Callback executed before the agent starts processing.\"\"\"\n",
        "    ticket_id = (\n",
        "        f\"TICKET-{SESSION_ID.split('_')[-1].upper()}\"  # Simulate getting ticket ID\n",
        "    )\n",
        "    print(f\"\\n[Callback Triggered: before_agent_callback]\")\n",
        "    print(f\"  -> Processing Ticket ID: {ticket_id}\")\n",
        "    # Example state modification: Store ticket ID\n",
        "    callback_context.state[\"ticket_id\"] = ticket_id\n",
        "    print(f\"  -> Agent '{callback_context.agent_name}' starting.\")\n",
        "    return None  # Return None to allow agent execution\n",
        "\n",
        "\n",
        "def log_after_agent(callback_context: CallbackContext) -> Optional[types.Content]:\n",
        "    \"\"\"Callback executed after the agent finishes processing.\"\"\"\n",
        "    ticket_id = callback_context.state.get(\"ticket_id\", \"UNKNOWN\")\n",
        "    print(f\"\\n[Callback Triggered: after_agent_callback]\")\n",
        "    print(f\"  -> Finished processing for Ticket ID: {ticket_id}.\")\n",
        "    # Example: Simulate updating ticket status in an external system\n",
        "    print(\n",
        "        f\"  -> Updating external system: Ticket {ticket_id} status set to 'Responded'.\"\n",
        "    )\n",
        "    # Example state modification\n",
        "    callback_context.state[\"processing_status\"] = \"completed\"\n",
        "    return None  # Return None, we don't want to append extra content here\n",
        "\n",
        "\n",
        "def log_before_model(\n",
        "    callback_context: CallbackContext, llm_request: LlmRequest\n",
        ") -> Optional[LlmResponse]:\n",
        "    \"\"\"Callback executed before sending the request to the LLM.\"\"\"\n",
        "    print(f\"\\n[Callback Triggered: before_model_callback]\")\n",
        "    print(f\"  -> Preparing to call LLM for agent '{callback_context.agent_name}'.\")\n",
        "    # Example: Log request details (be careful with PII in real scenarios)\n",
        "    # print(f\"  -> LLM Request Contents (brief): {str(llm_request.contents)[:200]}...\")\n",
        "    # Example: Add a safety reminder (Note: modifying system_instruction directly might be overwritten)\n",
        "    # llm_request.append_instructions([\"Remember to be helpful and safe.\"]) # Use append_instructions\n",
        "    print(f\"  -> Safety check/prompt augmentation applied (simulated).\")\n",
        "    return None  # Return None to proceed with LLM call\n",
        "\n",
        "\n",
        "def check_after_model(\n",
        "    callback_context: CallbackContext, llm_response: LlmResponse\n",
        ") -> Optional[LlmResponse]:\n",
        "    \"\"\"Callback executed after receiving the response from the LLM.\"\"\"\n",
        "    print(f\"\\n[Callback Triggered: after_model_callback]\")\n",
        "    print(f\"  -> Received LLM response for agent '{callback_context.agent_name}'.\")\n",
        "    # Example: Log response details (be careful with PII)\n",
        "    response_text = (\n",
        "        llm_response.content.parts[0].text\n",
        "        if llm_response.content and llm_response.content.parts\n",
        "        else \"[No Text]\"\n",
        "    )\n",
        "    print(f\"  -> LLM Raw Response (brief): {response_text[:100]}...\")\n",
        "    # Example: Simulate PII check\n",
        "    if \"password\" in response_text.lower() or \"credit card\" in response_text.lower():\n",
        "        print(\"  -> !! PII potentially detected in LLM response (simulated) !!\")\n",
        "        # Could modify response here, e.g., return an error or redacted text\n",
        "        # return LlmResponse(content=types.Content(parts=[types.Part(text=\"[Response redacted due to potential PII]\")]))\n",
        "    else:\n",
        "        print(\"  -> PII check passed (simulated).\")\n",
        "    return (\n",
        "        None  # Return None to use the original (or potentially modified) LLM response\n",
        "    )\n",
        "\n",
        "\n",
        "def validate_before_tool(\n",
        "    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext\n",
        ") -> Optional[Dict]:\n",
        "    \"\"\"Callback executed before a tool is called.\"\"\"\n",
        "    print(f\"\\n[Callback Triggered: before_tool_callback for Tool: '{tool.name}']\")\n",
        "    print(f\"  -> Attempting to call tool '{tool.name}' with args: {args}\")\n",
        "    # Example: Validate arguments\n",
        "    if tool.name == \"kb_search\" and \"keywords\" in args:\n",
        "        if not isinstance(args[\"keywords\"], list) or not args[\"keywords\"]:\n",
        "            print(\n",
        "                \"  -> !! Validation Failed: Keywords must be a non-empty list. Skipping tool call. !!\"\n",
        "            )\n",
        "            return {\n",
        "                \"error\": \"Invalid keywords provided for KB search.\"\n",
        "            }  # Return error to LLM\n",
        "        print(\"  -> Keyword validation passed.\")\n",
        "    return None  # Return None to proceed with actual tool execution\n",
        "\n",
        "\n",
        "def log_after_tool(\n",
        "    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext, tool_response: Dict\n",
        ") -> Optional[Dict]:\n",
        "    \"\"\"Callback executed after a tool has run.\"\"\"\n",
        "    print(f\"\\n[Callback Triggered: after_tool_callback for Tool: '{tool.name}']\")\n",
        "    print(f\"  -> Tool '{tool.name}' executed with args: {args}\")\n",
        "    print(f\"  -> Received tool response (brief): {str(tool_response)[:200]}...\")\n",
        "    # Example: Caching simulation (just log it)\n",
        "    print(f\"  -> Caching tool result (simulated).\")\n",
        "    # Example: Modify response if needed\n",
        "    # if \"solutions\" in tool_response and tool_response[\"solutions\"]:\n",
        "    #    tool_response[\"solutions\"].append(\"Also, try restarting your device.\") # Append suggestion\n",
        "    return None  # Return None to use the original (or modified) tool response\n",
        "\n",
        "\n",
        "# --- Agent Definition ---\n",
        "support_agent = LlmAgent(\n",
        "    model=GEMINI_2_FLASH,\n",
        "    name=AGENT_NAME,\n",
        "    instruction=\"\"\"You are an IT Support Agent. Your goal is to help users troubleshoot technical issues.\n",
        "1. Analyze the user's problem description (support ticket).\n",
        "2. Identify keywords related to the issue.\n",
        "3. If the issue relates to common hardware problems like 'screen', 'display', 'flickering', 'keyboard', use the `kb_search` tool with the identified keywords to find troubleshooting steps.\n",
        "4. Based on your analysis and any results from the `kb_search` tool, provide a clear, step-by-step response to the user.\n",
        "5. If the `kb_search` tool doesn't return useful information, state that and provide general troubleshooting advice (e.g., restart, check connections).\n",
        "\"\"\",\n",
        "    description=\"First-level IT support agent that analyzes issues and uses a knowledge base.\",\n",
        "    tools=[kb_search_tool],\n",
        "    # --- Assign Callbacks ---\n",
        "    before_agent_callback=log_before_agent,\n",
        "    after_agent_callback=log_after_agent,\n",
        "    before_model_callback=log_before_model,\n",
        "    after_model_callback=check_after_model,\n",
        "    before_tool_callback=validate_before_tool,\n",
        "    after_tool_callback=log_after_tool,\n",
        ")\n",
        "\n",
        "# --- Session and Runner Setup ---\n",
        "session_service = InMemorySessionService()\n",
        "# Ensure session is created before running\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=support_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# --- Agent Interaction Logic ---\n",
        "async def call_agent_and_show_flow(query):\n",
        "    print(f\"\\n--- Starting Workflow for Query: '{query}' ---\")\n",
        "    print(f\"\\n[User Submits Ticket: '{query}']\")\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    final_response_text = \"[Agent did not produce a final response text]\"\n",
        "\n",
        "    async for event in runner.run_async(\n",
        "        user_id=USER_ID, session_id=SESSION_ID, new_message=content\n",
        "    ):\n",
        "        # Print event details to trace the flow\n",
        "        # print(f\"\\nDEBUG Event: Author={event.author}, Partial={event.partial}, Final={event.is_final_response()}, Content={str(event.content)[:100]}...\")\n",
        "\n",
        "        if event.get_function_calls():\n",
        "            print(\n",
        "                f\"\\n[AFW: LLM decided to use Tool '{event.get_function_calls()[0].name}']\"\n",
        "            )\n",
        "            # Before tool callback is triggered internally by the runner/flow\n",
        "\n",
        "        elif event.get_function_responses():\n",
        "            print(\n",
        "                f\"\\n[AFW: Received result from Tool '{event.get_function_responses()[0].name}']\"\n",
        "            )\n",
        "            # After tool callback is triggered internally by the runner/flow\n",
        "            print(\n",
        "                \"  -> AFW: Sending tool result back to LLM for final response generation...\"\n",
        "            )\n",
        "\n",
        "        if event.is_final_response() and event.content and event.content.parts:\n",
        "            # Check if there's text before accessing parts[0]\n",
        "            if event.content.parts[0].text:\n",
        "                final_response_text = event.content.parts[0].text\n",
        "                print(f\"\\n[AFW: Sending Final Response to User]\")\n",
        "                print(f\"  -> Response: {final_response_text}\")\n",
        "            else:\n",
        "                print(\n",
        "                    f\"\\n[AFW: Final Response - Non-text content received: {event.content.parts}]\"\n",
        "                )\n",
        "                final_response_text = \"[Non-text final response]\"\n",
        "            # After agent callback will be triggered after this loop finishes internally\n",
        "\n",
        "    print(f\"\\n--- Workflow Finished for Query: '{query}' ---\")\n",
        "    # Retrieve final state to show callback modification\n",
        "    final_session = session_service.get_session(\n",
        "        app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        "    )\n",
        "    print(\n",
        "        f\"Final Session State (example): ticket_id='{final_session.state.get('ticket_id')}', status='{final_session.state.get('processing_status')}'\"\n",
        "    )\n",
        "    return final_response_text\n",
        "\n",
        "\n",
        "await call_agent_and_show_flow(\"Help! My computer screen keeps flickering constantly.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPo0-P_AwXm6"
      },
      "source": [
        "###  Quickstart session, states and SessionService\n",
        "\n",
        "- How to retreive session state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp3LOwJN3VVH",
        "outputId": "35f7180d-5965-466d-e940-bf30da2e32f0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types\n",
        "\n",
        "# --- Constants ---\n",
        "APP_NAME = \"capital_finder_app\"\n",
        "USER_ID = \"quickstart_user\"\n",
        "SESSION_ID = \"session_abc\"\n",
        "MODEL = \"gemini-2.0-flash-001\"\n",
        "\n",
        "# Agent\n",
        "capital_agent = LlmAgent(\n",
        "    model=MODEL,\n",
        "    name=\"CapitalFinderAgent\",\n",
        "    instruction=\"\"\"You are an agent that finds the capital of a given country.\n",
        "    When asked for the capital, respond *only* with the name of the capital city.\n",
        "    \"\"\",\n",
        "    output_key=\"capital_city\",  # Save the agent's final response text to state['capital_city']\n",
        ")\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=capital_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "def call_agent(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"\\nAgent Response: \", final_response)\n",
        "\n",
        "\n",
        "initial_session = session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "print(f\"Initial Session State: {initial_session.state}\")  # Should be empty {}\n",
        "\n",
        "call_agent(\"What is the capital of france?\")\n",
        "\n",
        "final_session = session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "print(\n",
        "    f\"Final Session State: {final_session.state}\"\n",
        ")  # Should now contain {'capital_city': 'Paris'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl5zb-k4MTak"
      },
      "source": [
        "### Session State - State Manupilation\n",
        "\n",
        "- How to manually modify session state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jtLbWd9-cqih"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.agents import LlmAgent\n",
        "from google.genai import types\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.events import Event, EventActions\n",
        "\n",
        "# --- Constants ---\n",
        "APP_NAME = \"task_manager_app\"\n",
        "USER_ID = \"test_user\"\n",
        "AGENT_NAME = \"task_manager_agent\"\n",
        "MODEL_NAME = \"gemini-2.0-flash-001\"  # Or any suitable model\n",
        "\n",
        "# --- Agent Definition ---\n",
        "#  Simplified instruction, as we're handling logic directly\n",
        "task_agent = LlmAgent(\n",
        "    model=MODEL_NAME,\n",
        "    name=AGENT_NAME,\n",
        "    instruction=\"\"\"You are a Task Management Agent. Respond to user requests to manage tasks.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "\n",
        "def add_task(session, task_description):\n",
        "    \"\"\"Adds a task to the task list.\"\"\"\n",
        "    tasks = session.state.get(\"user:tasks\", [])  # Get current tasks (or empty list)\n",
        "    new_task_id = len(tasks) + 1\n",
        "    new_task = {\"id\": new_task_id, \"description\": task_description, \"status\": \"pending\"}\n",
        "    tasks.append(new_task)\n",
        "    # Use EventActions to update the state (delta update)\n",
        "    add_event = Event(\n",
        "        author=\"agent\", actions=EventActions(state_delta={\"user:tasks\": tasks})\n",
        "    )\n",
        "    session_service.append_event(session, add_event)\n",
        "    return f\"Task '{task_description}' added with ID {new_task_id}.\"\n",
        "\n",
        "\n",
        "def modify_task(session, task_id, new_status):\n",
        "    \"\"\"Modifies the status of a task.\"\"\"\n",
        "    tasks = session.state.get(\"user:tasks\", [])\n",
        "    try:\n",
        "        task_id = int(task_id)  # Ensure task_id is an integer\n",
        "    except ValueError:\n",
        "        return \"Invalid task ID. Please provide a number.\"\n",
        "\n",
        "    for i, task in enumerate(tasks):\n",
        "        if task[\"id\"] == task_id:\n",
        "            tasks[i][\"status\"] = new_status\n",
        "            # Update state via EventActions\n",
        "            modify_event = Event(\n",
        "                author=\"agent\", actions=EventActions(state_delta={\"user:tasks\": tasks})\n",
        "            )\n",
        "            session_service.append_event(session, modify_event)\n",
        "            return f\"Task {task_id} status updated to '{new_status}'.\"\n",
        "    return f\"Task with ID {task_id} not found.\"\n",
        "\n",
        "\n",
        "def delete_task(session, task_id):\n",
        "    \"\"\"Deletes a task from the task list.\"\"\"\n",
        "    tasks = session.state.get(\"user:tasks\", [])\n",
        "    try:\n",
        "        task_id = int(task_id)\n",
        "    except ValueError:\n",
        "        return \"Invalid task ID.  Please provide a number.\"\n",
        "\n",
        "    updated_tasks = [task for task in tasks if task[\"id\"] != task_id]\n",
        "    if len(updated_tasks) < len(tasks):\n",
        "        # Update state via EventActions\n",
        "        delete_event = Event(\n",
        "            author=\"agent\",\n",
        "            actions=EventActions(state_delta={\"user:tasks\": updated_tasks}),\n",
        "        )\n",
        "        session_service.append_event(session, delete_event)\n",
        "        return f\"Task {task_id} deleted.\"\n",
        "    return f\"Task with ID {task_id} not found.\"\n",
        "\n",
        "\n",
        "def list_tasks(session):\n",
        "    \"\"\"Lists all tasks for the user.\"\"\"\n",
        "    tasks = session.state.get(\"user:tasks\", [])\n",
        "    if not tasks:\n",
        "        return \"You have no tasks.\"\n",
        "    task_list_str = \"\\n\".join(\n",
        "        f\"{task['id']}: {task['description']} ({task['status']})\" for task in tasks\n",
        "    )\n",
        "    return f\"Your tasks:\\n{task_list_str}\"\n",
        "\n",
        "\n",
        "def call_agent(user_input, session):\n",
        "    \"\"\"Sends user input to the agent and processes events.\"\"\"\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=user_input)])\n",
        "    events = runner.run(\n",
        "        user_id=USER_ID, session_id=session.id, new_message=content\n",
        "    )  # session.id, not SESSION_ID\n",
        "\n",
        "    final_response_text = \"\"\n",
        "    for event in events:\n",
        "        if event.content and event.content.role == \"model\":\n",
        "            final_response_text = event.content.parts[0].text\n",
        "            break  # Exit loop after getting the final response.\n",
        "\n",
        "    return final_response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgLYUT1Ycqb_",
        "outputId": "0ac9b658-9f92-48d5-86ba-4c9b1b0906b2"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 1. Create a Session (with initial state, if any)\n",
        "#  demonstrates: create_session, InMemorySessionService, initial state\n",
        "USER_ID = \"test_user2\"\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID\n",
        ")  #  Let the service generate the ID\n",
        "\n",
        "print(f\"Created session with ID: {session.id}\")\n",
        "runner = Runner(agent=task_agent, app_name=APP_NAME, session_service=session_service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k5wliFueuF_U",
        "outputId": "558911ac-d631-41d0-ff5f-f63e06d39f32"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "session.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G8I0MtT4Gfy",
        "outputId": "b2dba833-1a26-423a-cbf7-27ef7cecfbba"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "retrieved_session = session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=session.id\n",
        ")\n",
        "print(f\"\\nRetrieved session state:\")\n",
        "retrieved_session.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "tGg1H36a2k-8",
        "outputId": "8e47f9f9-2882-4e0e-ee5b-b3e625a9f25e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "print(\"\\nAdding tasks directly to state via Function...\")\n",
        "\n",
        "add_task(session, \"Buy milk\")\n",
        "add_task(session, \"Walk the dog\")\n",
        "add_task(session, \"Prepare presentation\")\n",
        "add_task(session, \"Buy groceries\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSK4sovb1OWx",
        "outputId": "3ef0996b-e931-4758-e456-1d0afdf2ee37"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 3. Retrieve and display the session (demonstrates get_session)\n",
        "retrieved_session = session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=session.id\n",
        ")\n",
        "print(f\"\\nRetrieved session state:\")\n",
        "retrieved_session.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUOEucZl1VdT",
        "outputId": "24dd38a5-7f5a-4dcc-c238-917d19f45a26"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 4. List tasks (demonstrates accessing state)\n",
        "print(\"\\nListing tasks...\")\n",
        "print(list_tasks(retrieved_session))  # Using a helper, accessing state directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3EWU1Tb14Vn",
        "outputId": "f945c5dd-c3c7-4b64-9752-136ff6a74b3c"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 5. Modify a task (demonstrates state modification)\n",
        "print(\"\\nModifying task 2...\")\n",
        "print(modify_task(retrieved_session, \"2\", \"completed\"))\n",
        "retrieved_session = session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=session.id\n",
        ")\n",
        "print(f\"Modified session state:\")\n",
        "retrieved_session.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yHQmUMB16c4",
        "outputId": "ab0f2fd1-1d4a-4831-84b6-cdc1fac331cc"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 6. Delete a task (demonstrates state deletion)\n",
        "print(\"\\nDeleting task 1...\")\n",
        "print(delete_task(retrieved_session, \"1\"))\n",
        "retrieved_session = session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=session.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFHKk3zA18nz",
        "outputId": "3d287272-a29f-4b79-a465-3661acf1845f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "print(f\"Session state after deletion:\")\n",
        "retrieved_session.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTsLpN4a2Ddr",
        "outputId": "481bcb3b-d3cd-4580-c90d-2b15d8998f87"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 7. List sessions for the user (demonstrates list_sessions)\n",
        "# Demonstrates:  list_sessions\n",
        "print(f\"\\nSessions for user {USER_ID}:\")\n",
        "session_service.list_sessions(app_name=APP_NAME, user_id=USER_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjZI2ZgK2GDc",
        "outputId": "6a2ded3d-6d11-49eb-8ad5-39783b63c9fa"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 8. Delete a session (demonstrates delete_session).\n",
        "session_service.delete_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=session.id\n",
        ")\n",
        "print(f\"\\nDeleted session: {session.id}\")\n",
        "retrieved_session = session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=session.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p4fVhCh2Iho",
        "outputId": "e6d7a072-80e2-422b-f951-6ec993a716bb"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "if retrieved_session:  # Should be None.\n",
        "    print(retrieved_session)\n",
        "else:\n",
        "    print(\"Session deleted successfully, as could not be retrieved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "648gwMHOMNWx"
      },
      "source": [
        "### Session State - delta_states (OPTIONAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbf_eXbYHfYp",
        "outputId": "c5a07f45-7747-4a69-d868-ffd6adde2af0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.sessions import InMemorySessionService\n",
        "\n",
        "\n",
        "# Create the session service\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "# Create a session (with initial state)\n",
        "session = session_service.create_session(\n",
        "    app_name=\"my_app\",\n",
        "    user_id=\"user1\",\n",
        "    state={\"order_status\": \"pending\", \"items\": [\"shirt\"], \"notes\": \"Initial order\"},\n",
        ")\n",
        "\n",
        "# --- Direct State Manipulation (Generally NOT Recommended) ---\n",
        "\n",
        "# 1. Retrieve the session (to get the current state)\n",
        "retrieved_session = session_service.get_session(\n",
        "    app_name=\"my_app\", user_id=\"user1\", session_id=session.id\n",
        ")\n",
        "\n",
        "# 2. Access the state dictionary directly\n",
        "current_state = retrieved_session.state\n",
        "\n",
        "# --- Simulating a Delta Update (Directly) ---\n",
        "\n",
        "# Directly modify the state dictionary as if applying a state_delta:\n",
        "current_state[\"order_status\"] = \"shipped\"  # Update existing key\n",
        "current_state[\"tracking_number\"] = \"XYZ456\"  # Add a new key\n",
        "current_state[\"items\"].append(\"pants\")  # Modify a list (append)\n",
        "del current_state[\"notes\"]  # Delete a key\n",
        "\n",
        "# The changes are reflected *immediately* in the retrieved_session (with InMemorySessionService)\n",
        "print(retrieved_session.state)\n",
        "\n",
        "# --- Demonstrating State Prefixes (Directly) ---\n",
        "# We need to use setdefault to properly initialize nested dictionaries.\n",
        "print(\"haha\", session_service.app_state.setdefault(\"my_app\", {}))\n",
        "print(\n",
        "    \"haha\", session_service.user_state.setdefault(\"my_app\", {}).setdefault(\"user1\", {})\n",
        ")\n",
        "session_service.app_state.setdefault(\"my_app\", {})[\"max_retries\"] = 3  # app-level\n",
        "session_service.user_state.setdefault(\"my_app\", {}).setdefault(\"user1\", {})[\n",
        "    \"pref_contact\"\n",
        "] = \"email\"\n",
        "current_state[\"temp:request_id\"] = \"temp_value\"\n",
        "\n",
        "print(\"\\nState with prefixes added:\")\n",
        "print(retrieved_session.state)  # temp wont be there\n",
        "\n",
        "retrieved_session = session_service.get_session(\n",
        "    app_name=\"my_app\", user_id=\"user1\", session_id=session.id\n",
        ")\n",
        "print(\"\\nState after retrieval (temp should be gone):\")\n",
        "\n",
        "print(retrieved_session.state)\n",
        "\n",
        "print(\"\\nApp State:\")\n",
        "print(session_service.app_state)\n",
        "print(\"\\nUser State:\")\n",
        "print(session_service.user_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU_OHcRejR6j"
      },
      "source": [
        "### Accessing Session Properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUzzDIZyjSQL",
        "outputId": "8a0695ab-755c-4397-e368-ed751758c8fc"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from google.adk.sessions import InMemorySessionService\n",
        "\n",
        "\n",
        "# Create a simple session to examine its properties\n",
        "temp_service = InMemorySessionService()\n",
        "example_session = temp_service.create_session(\n",
        "    app_name=\"my_app\", user_id=\"example_user\", state={\"initial_value\": 1}\n",
        ")\n",
        "\n",
        "print(f\"--- Examining Session Properties ---\")\n",
        "print(f\"ID (`id`):                {example_session.id}\")  # Unique identifier\n",
        "print(\n",
        "    f\"Application Name (`app_name`): {example_session.app_name}\"\n",
        ")  # Which app it belongs to\n",
        "print(f\"User ID (`user_id`):         {example_session.user_id}\")  # Who the user is\n",
        "print(\n",
        "    f\"State (`state`):           {example_session.state}\"\n",
        ")  # The dynamic 'notes' dictionary\n",
        "print(\n",
        "    f\"Events (`events`):         {example_session.events}\"\n",
        ")  # The conversation history (initially empty)\n",
        "print(\n",
        "    f\"Last Update (`last_update_time`): {example_session.last_update_time:.2f}\"\n",
        ")  # When it was last triggered\n",
        "print(f\"---------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYc-fk34FL2h"
      },
      "source": [
        "### Using InMemorySessionService Methods\n",
        "\n",
        "- Adding event\n",
        "- Update state with `state_delta`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOOfCY_k59Bt",
        "outputId": "4742d4d6-dc91-4682-8486-8f4624b13322"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Example: Using InMemorySessionService Methods\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.events import Event, EventActions\n",
        "from google.genai import types\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "print(\"\\n--- Demonstrating InMemorySessionService ---\")\n",
        "\n",
        "# 1. Instantiate\n",
        "session_service = InMemorySessionService()\n",
        "app_name, user_id = \"memory_app\", \"user_mem\"\n",
        "session_id = \"mem_session_1\"\n",
        "\n",
        "# 2. Create Session\n",
        "current_session = session_service.create_session(\n",
        "    app_name=app_name, user_id=user_id, session_id=session_id, state={\"counter\": 0}\n",
        ")\n",
        "print(f\"Created Session: ID={current_session.id}, State={current_session.state}\")\n",
        "\n",
        "# 3. Append Event with State Delta\n",
        "user_event = Event(\n",
        "    invocation_id=\"inv_1\",\n",
        "    author=\"user\",\n",
        "    content=types.Content(parts=[types.Part(text=\"Increment\")]),\n",
        ")\n",
        "session_service.append_event(current_session, user_event)  # No state change yet\n",
        "\n",
        "agent_event = Event(\n",
        "    invocation_id=\"inv_2\",\n",
        "    author=\"agent\",\n",
        "    actions=EventActions(state_delta={\"counter\": 1}),  # Increment counter\n",
        ")\n",
        "session_service.append_event(current_session, agent_event)\n",
        "print(f\"Appended Event, state['counter'] should be 1\")\n",
        "\n",
        "# 4. Get Session\n",
        "retrieved_session = session_service.get_session(\n",
        "    app_name=app_name, user_id=user_id, session_id=session_id\n",
        ")\n",
        "print(f\"Retrieved Session: ID={retrieved_session.id}, State={retrieved_session.state}\")\n",
        "print(\n",
        "    f\"Events in session: {len(retrieved_session.events)}\"\n",
        ")  # Shows 2 events were added\n",
        "\n",
        "# 5. List Sessions\n",
        "session_list = session_service.list_sessions(app_name=app_name, user_id=user_id)\n",
        "print(f\"List Sessions for {user_id}: {session_list}\")\n",
        "\n",
        "# 6. Delete Session\n",
        "session_service.delete_session(\n",
        "    app_name=app_name, user_id=user_id, session_id=session_id\n",
        ")\n",
        "print(f\"Deleted Session: {session_id}\")\n",
        "\n",
        "# 7. Get Session (should fail)\n",
        "deleted_session = session_service.get_session(\n",
        "    app_name=app_name, user_id=user_id, session_id=session_id\n",
        ")\n",
        "print(\n",
        "    f\"Retrieve after delete: {'Session found (unexpected!)' if deleted_session else 'Session not found (correct)'}\"\n",
        ")\n",
        "print(\"------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQRDTzpZFIBi"
      },
      "source": [
        "###  Using DatabaseSessionService Methods (with SQLite for demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmah-tOJBgl0",
        "outputId": "aff0690d-d516-4c2c-8f72-44dc5db1974e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Example: Using DatabaseSessionService Methods (with SQLite for demo)\n",
        "\n",
        "# NOTE: Requires `sqlalchemy` to be installed.\n",
        "# NOTE: This creates a file 'db_sessions_demo.db' in the current directory.\n",
        "from google.adk.sessions import DatabaseSessionService\n",
        "from google.adk.events import Event, EventActions\n",
        "from google.genai import types  # Make sure types is imported\n",
        "import time\n",
        "import uuid\n",
        "import os  # To manage the demo database file\n",
        "\n",
        "print(\"\\n--- Demonstrating DatabaseSessionService (SQLite) ---\")\n",
        "DB_FILE = \"./db_sessions_demo.db\"  # Define path for the database file\n",
        "DB_DIR = os.path.dirname(DB_FILE)  # Get directory path\n",
        "\n",
        "# Ensure the directory exists (useful if DB_FILE includes subdirectories)\n",
        "if DB_DIR and not os.path.exists(DB_DIR):\n",
        "    os.makedirs(DB_DIR)\n",
        "    print(f\"Created directory: {DB_DIR}\")\n",
        "\n",
        "# Remove the database file if it exists from a previous run for a clean demo\n",
        "if os.path.exists(DB_FILE):\n",
        "    os.remove(DB_FILE)\n",
        "    print(f\"Removed existing demo DB file: {DB_FILE}\")\n",
        "\n",
        "# 1. Instantiate (using SQLite file)\n",
        "# The DatabaseSessionService's __init__ method will handle DB/table creation.\n",
        "db_service = DatabaseSessionService(db_url=f\"sqlite:///{DB_FILE}\")\n",
        "print(f\"Instantiated DatabaseSessionService. DB file '{DB_FILE}' ensured/created.\")\n",
        "\n",
        "APP_DB, USER_DB = \"db_app\", \"user_db\"\n",
        "SESSION_ID_DB = \"db_session_1\"\n",
        "\n",
        "# 2. Create Session\n",
        "session_db = db_service.create_session(\n",
        "    app_name=APP_DB, user_id=USER_DB, session_id=SESSION_ID_DB, state={\"status\": \"new\"}\n",
        ")\n",
        "print(f\"Created Session: ID={session_db.id}, State={session_db.state}\")\n",
        "\n",
        "# 3. Append Event with State Delta\n",
        "# *** FIX: Ensure event has a 'content' object, even if minimal ***\n",
        "event_db_1 = Event(\n",
        "    invocation_id=\"inv_db1\",\n",
        "    author=\"agent\",\n",
        "    content=types.Content(\n",
        "        parts=[types.Part(text=\"System update: Processing\")]\n",
        "    ),  # Add content\n",
        "    actions=EventActions(state_delta={\"status\": \"processing\", \"db_key\": \"db_val\"}),\n",
        ")\n",
        "# Note: append_event updates the state in the DB and the passed session's last_update_time\n",
        "db_service.append_event(session_db, event_db_1)\n",
        "print(f\"Appended Event, state should be updated in the database.\")\n",
        "\n",
        "# 4. Get Session (re-fetch from DB to see persisted changes)\n",
        "# Note: Must re-fetch session to see DB changes reflected in the object state\n",
        "retrieved_session_db = db_service.get_session(\n",
        "    app_name=APP_DB, user_id=USER_DB, session_id=SESSION_ID_DB\n",
        ")\n",
        "print(\n",
        "    f\"Retrieved Session: ID={retrieved_session_db.id}, State={retrieved_session_db.state}\"\n",
        ")\n",
        "# Note: Events are not automatically loaded by get_session in this implementation by default.\n",
        "\n",
        "# 5. List Sessions\n",
        "sessions_list_db = db_service.list_sessions(app_name=APP_DB, user_id=USER_DB)\n",
        "print(f\"List Sessions for {USER_DB}: {sessions_list_db}\")\n",
        "\n",
        "# 6. List Events (Not Implemented in DatabaseSessionService base implementation)\n",
        "try:\n",
        "    db_service.list_events(app_name=APP_DB, user_id=USER_DB, session_id=SESSION_ID_DB)\n",
        "except NotImplementedError as e:\n",
        "    print(f\"List Events: Received NotImplementedError (as expected in base class)\")\n",
        "except AttributeError as e:\n",
        "    print(\n",
        "        f\"List Events: Method not found or not implemented (as expected in base class)\"\n",
        "    )\n",
        "\n",
        "# 7. Delete Session\n",
        "db_service.delete_session(app_name=APP_DB, user_id=USER_DB, session_id=SESSION_ID_DB)\n",
        "print(f\"Deleted Session: {SESSION_ID_DB}\")\n",
        "\n",
        "# 8. Get Session (should fail)\n",
        "deleted_session_check_db = db_service.get_session(\n",
        "    app_name=APP_DB, user_id=USER_DB, session_id=SESSION_ID_DB\n",
        ")\n",
        "print(\n",
        "    f\"Retrieve after delete: {'Session found (unexpected!)' if deleted_session_check_db else 'Session not found (correct)'}\"\n",
        ")\n",
        "\n",
        "# Cleanup demo file (optional, good practice for demos)\n",
        "# if os.path.exists(DB_FILE):\n",
        "#     os.remove(DB_FILE)\n",
        "#     print(f\"Cleaned up demo DB file: {DB_FILE}\")\n",
        "print(\"--------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtgJPaV1Qw6j"
      },
      "source": [
        "### LlMAgent with Antrhopic (3rd Party Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptc7IKdrQxLx",
        "outputId": "0a39001a-a64f-4639-b09c-34f581413e08"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import warnings\n",
        "\n",
        "# --- GCP/Vertex AI Configuration ---\n",
        "# Make sure these are set in your environment OR uncomment and set here\n",
        "# os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"your-project-id\"\n",
        "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = (\n",
        "    \"us-east5\"  # Make sure its us-east5 or europe-west1\n",
        ")\n",
        "\n",
        "# --- ADK Imports ---\n",
        "from google.adk.agents import Agent, LlmAgent  # Using LlmAgent directly\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types\n",
        "from google.adk.models.anthropic_llm import Claude\n",
        "from google.adk.models.registry import LLMRegistry\n",
        "\n",
        "# Manually register the Claude model class with the registry\n",
        "# This step is crucial if the framework doesn't do it automatically\n",
        "LLMRegistry.register(Claude)\n",
        "\n",
        "\n",
        "# --- Constants ---\n",
        "APP_NAME = \"anthropic_capital_app\"\n",
        "USER_ID = \"anthropic_user\"\n",
        "SESSION_ID = \"anthropic_session_1\"\n",
        "AGENT_NAME = \"claude_capital_agent\"\n",
        "# --- Anthropic Model Name (via Vertex AI) ---\n",
        "# Use the model identifier available in your Vertex AI region.\n",
        "# Example: Claude 3.5 Sonnet. Check Vertex AI documentation for available models.\n",
        "ANTHROPIC_MODEL = \"claude-3-7-sonnet@20250219\"\n",
        "# You might need to adjust this based on availability in your specific GCP project/location.\n",
        "# Other possibilities: \"claude-3-haiku@...\", \"claude-3-opus@...\"\n",
        "\n",
        "# --- Agent Definition ---\n",
        "# Simplest agent: takes user input, uses the LLM directly to answer.\n",
        "capital_agent = LlmAgent(\n",
        "    model=ANTHROPIC_MODEL,  # Specify the Anthropic model identifier\n",
        "    name=AGENT_NAME,\n",
        "    instruction=\"You are a helpful assistant. When asked for the capital of a country, provide only the name of the capital city.\",\n",
        "    description=\"An agent that provides the capital city of a country using an Anthropic model.\",\n",
        "    # No tools needed for this simple task\n",
        "    tools=[],\n",
        ")\n",
        "\n",
        "# --- Session and Runner Setup ---\n",
        "session_service = InMemorySessionService()\n",
        "# Ensure session is created before running\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=capital_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# --- Agent Interaction Logic ---\n",
        "# Using async version as it's preferred\n",
        "async def call_agent_async(query):\n",
        "    print(f\"\\nUser Query: {query}\")\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    final_response_text = \"Agent did not produce a final response.\"\n",
        "    try:\n",
        "        async for event in runner.run_async(\n",
        "            user_id=USER_ID, session_id=SESSION_ID, new_message=content\n",
        "        ):\n",
        "            if event.is_final_response() and event.content and event.content.parts:\n",
        "                final_response_text = event.content.parts[0].text\n",
        "                print(f\"Agent Response: {final_response_text}\")\n",
        "                # Break after final response for simplicity in this example\n",
        "                break\n",
        "            elif event.error_message:\n",
        "                final_response_text = f\"Agent Error: {event.error_message}\"\n",
        "                print(final_response_text)\n",
        "                break\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during agent execution: {e}\")\n",
        "        final_response_text = f\"Execution Error: {e}\"\n",
        "\n",
        "    return final_response_text\n",
        "\n",
        "\n",
        "# --- Example Usage ---\n",
        "async def run_example():\n",
        "    print(\"--- Running Anthropic Agent Example ---\")\n",
        "    print(f\"Using model: {ANTHROPIC_MODEL}\")\n",
        "    print(\n",
        "        f\"Make sure GCP Project '{os.environ['GOOGLE_CLOUD_PROJECT']}' and Location '{os.environ['GOOGLE_CLOUD_LOCATION']}' are correct and the model is available there.\"\n",
        "    )\n",
        "    print(\n",
        "        \"Ensure you are authenticated with GCP (e.g., `gcloud auth application-default login`).\"\n",
        "    )\n",
        "\n",
        "    await call_agent_async(\"What is the capital of France?\")\n",
        "    await call_agent_async(\"What's the capital of Japan?\")\n",
        "    await call_agent_async(\"Tell me the capital of Germany.\")\n",
        "    print(\"--- Example Finished ---\")\n",
        "\n",
        "\n",
        "await run_example()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFLdX7tcIRuz"
      },
      "source": [
        "### Artifact Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def before_model_callback(callback_context, llm_request):\n",
        "    print(\n",
        "        f\"Before Model Callback: Agent {callback_context._invocation_context.agent.name}, Request: {llm_request.contents}\"\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "def after_model_callback(callback_context, llm_response):\n",
        "    print(\n",
        "        f\"After Model Callback: Agent {callback_context._invocation_context.agent.name}, Response: {llm_response.content}\"\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "def before_tool_callback(tool, args, tool_context):\n",
        "    print(f\"Before Tool Callback: Tool {tool.name}, Args: {args}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def after_tool_callback(tool, args, tool_context, tool_response):\n",
        "    print(f\"After Tool Callback: Tool {tool.name}, Response: {tool_response}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def before_agent_callback(callback_context):\n",
        "    print(\n",
        "        f\"Before Agent Callback: Agent {callback_context._invocation_context.agent.name}\"\n",
        "    )\n",
        "    return None\n",
        "\n",
        "\n",
        "def after_agent_callback(callback_context):\n",
        "    print(\n",
        "        f\"After Agent Callback: Agent {callback_context._invocation_context.agent.name}\"\n",
        "    )\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.adk.runners import Runner\n",
        "from google.adk.artifacts import InMemoryArtifactService\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.tools import ToolContext\n",
        "\n",
        "async def save_dummy_report(tool_context: ToolContext):\n",
        "    \"\"\"\n",
        "    Saves a dummy PDF report as an artifact.\n",
        "    \"\"\"\n",
        "\n",
        "    report_artifact = types.Part.from_bytes(\n",
        "        data=b\"this is dummy content\", mime_type=\"application/pdf\"\n",
        "    )\n",
        "    filename = \"generated_report.pdf\"\n",
        "    print(\"Generating dummy pdf\")\n",
        "    version = await tool_context.save_artifact(filename=filename, artifact=report_artifact)\n",
        "    return {\"status\": \"ok\", \"filename\": filename}\n",
        "\n",
        "async def load_dummy_report(tool_context: ToolContext)->str:\n",
        "    \"\"\"\n",
        "    Loads the dummy PDF report artifact from storage.\n",
        "    \"\"\"\n",
        "    filename = \"generated_report.pdf\"\n",
        "    report_artifact = await tool_context.load_artifact(filename=filename)\n",
        "\n",
        "    if report_artifact and report_artifact.inline_data:\n",
        "        print(f\"MIME Type: {report_artifact.inline_data.mime_type}\")\n",
        "        pdf_bytes = report_artifact.inline_data.data\n",
        "        print(f\"Report size: {len(pdf_bytes)} bytes.\")\n",
        "        return {\"status\": \"ok\", \"filename\": filename}\n",
        "    else:\n",
        "        return {\"status\": \"ok\", \"filename\":\"No artifact found\"}\n",
        "\n",
        "async def save_memory(\n",
        "    tool_context: ToolContext,\n",
        ") -> dict:\n",
        "    \"\"\"Dummy function to save a dummy pdf\"\"\"\n",
        "    filename = \"test.pdf\"\n",
        "    report_artifact = types.Part.from_bytes(\n",
        "        data=b\"this is dummy content\", mime_type=\"application/pdf\"\n",
        "    )\n",
        "    await tool_context.save_artifact(filename, report_artifact)\n",
        "    return {\"status\": \"ok\", \"filename\": filename}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating dummy pdf\n",
            "Agent Response:  OK. I have saved a dummy PDF report as an artifact with filename `generated_report.pdf`. Next, please ask me to load the report.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google.adk.sessions import InMemorySessionService\n",
        "import uuid\n",
        "from google.adk.runners import Runner\n",
        "\n",
        "session_service = InMemorySessionService()\n",
        "artifact_service = InMemoryArtifactService()\n",
        "\n",
        "# Required. Unique identifier for the application.\n",
        "APP_NAME = \"weather_app\"\n",
        "# Required. Identifier for the user interacting with the agent. This is a dynamic variable.\n",
        "USER_ID = \"12345\"\n",
        "\n",
        "SESSION_ID = f\"session_{uuid.uuid4()}\"  # Use a dynamic session ID\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "\n",
        "# Your agent definition\n",
        "root_agent = LlmAgent(\n",
        "    name=\"my_agent\",\n",
        "    model=GEMINI_2_FLASH,\n",
        "    tools=[save_dummy_report, load_dummy_report],\n",
        "    instruction=\"You are a helpful assistant that saves a dummy PDF report as an artifact, and then read it back to user.\",\n",
        ")\n",
        "\n",
        "runner = Runner(\n",
        "    agent=root_agent,\n",
        "    app_name=APP_NAME,\n",
        "    session_service=session_service,\n",
        "    artifact_service=artifact_service,\n",
        ")\n",
        "\n",
        "\n",
        "def call_agent(user_query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=user_query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n",
        "\n",
        "\n",
        "# call_agent(\"load and retrieve the dummy report\")\n",
        "call_agent(\"generating save dummy pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'weather_app/12345/session_533d576a-ff80-4d08-b9a3-9ddc1a8503d2/generated_report.pdf': [Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=Blob(data=b'this is dummy content', mime_type='application/pdf'), text=None)]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "artifact_service.artifacts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4eum1l5eLhI"
      },
      "source": [
        "## Non-LLM Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2hOcAEld7oT"
      },
      "source": [
        "### Multi-Agent - SequenceAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XihTsvVHU8v",
        "outputId": "f40af520-c4d0-4742-dc4b-0415c19ede01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event: AgentA: Agent A: Starting...\n",
            "Event: AgentA: Agent A: Finishing...\n",
            "Event: AgentB: Agent B: Starting...\n",
            "Event: AgentB: Agent B: Finishing...\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from uuid import uuid4\n",
        "from google.adk.agents.base_agent import BaseAgent\n",
        "from google.adk.agents.sequential_agent import SequentialAgent\n",
        "from google.adk.agents.invocation_context import (\n",
        "    InvocationContext,\n",
        "    new_invocation_context_id,\n",
        ")\n",
        "from google.adk.events import Event\n",
        "from typing_extensions import override\n",
        "from google.adk.sessions.in_memory_session_service import InMemorySessionService\n",
        "from google.adk.sessions.session import Session\n",
        "from google.genai import types\n",
        "from typing import AsyncGenerator\n",
        "\n",
        "\n",
        "class AgentA(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Starting...\")]),\n",
        "        )\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "class AgentB(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Starting...\")]),\n",
        "        )\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "async def main():\n",
        "    # Create a session\n",
        "    session_service = InMemorySessionService()\n",
        "    session: Session = session_service.create_session(\n",
        "        app_name=\"test_app\", user_id=\"test_user\"\n",
        "    )\n",
        "\n",
        "    agent_a = AgentA(name=\"AgentA\")\n",
        "    agent_b = AgentB(name=\"AgentB\")\n",
        "\n",
        "    # Create the SequentialAgent\n",
        "    sequential_agent = SequentialAgent(\n",
        "        name=\"SequentialAgent\", sub_agents=[agent_a, agent_b]\n",
        "    )\n",
        "\n",
        "    # Create InvocationContext\n",
        "    ctx = InvocationContext(\n",
        "        invocation_id=new_invocation_context_id(),\n",
        "        session_service=session_service,\n",
        "        session=session,\n",
        "        agent=sequential_agent,\n",
        "        user_content=types.Content(parts=[types.Part(text=\"execute\")]),\n",
        "    )\n",
        "\n",
        "    # Run the SequentialAgent\n",
        "    async for event in sequential_agent.run_async(ctx):\n",
        "        if event.content and event.content.parts:\n",
        "            print(f\"Event: {event.author}: {event.content.parts[0].text}\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ZyIVLGnaPG"
      },
      "source": [
        "### Passing state between Children"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfr_cRxsXSo_",
        "outputId": "d8d20543-b2e2-4841-8958-cd7dfc16e717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event: AgentA: Agent A: Starting...\n",
            "Event: AgentA: Agent A: Finishing...\n",
            "Event: AgentB: Agent B: Starting...\n",
            "Event: AgentB: Agent B: Received value: Hello from Agent A!\n",
            "Event: AgentB: Agent B: Finishing...\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from uuid import uuid4\n",
        "from google.adk.agents.base_agent import BaseAgent\n",
        "from google.adk.agents.sequential_agent import SequentialAgent\n",
        "from google.adk.agents.invocation_context import (\n",
        "    InvocationContext,\n",
        "    new_invocation_context_id,\n",
        ")\n",
        "from google.adk.events import Event\n",
        "from typing_extensions import override\n",
        "from google.adk.sessions.in_memory_session_service import InMemorySessionService\n",
        "from google.adk.sessions.session import Session\n",
        "from google.genai import types\n",
        "from typing import AsyncGenerator\n",
        "\n",
        "\n",
        "class AgentA(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Starting...\")]),\n",
        "        )\n",
        "        # Set a value in the session state\n",
        "        ctx.session.state[\"agent_a_value\"] = \"Hello from Agent A!\"\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "class AgentB(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Starting...\")]),\n",
        "        )\n",
        "        # Retrieve the value from the session state\n",
        "        agent_a_value = ctx.session.state.get(\"agent_a_value\")\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(\n",
        "                parts=[types.Part(text=f\"Agent B: Received value: {agent_a_value}\")]\n",
        "            ),\n",
        "        )\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "async def main():\n",
        "    # Create a session\n",
        "    session_service = InMemorySessionService()\n",
        "    session: Session = session_service.create_session(\n",
        "        app_name=\"test_app\", user_id=\"test_user\"\n",
        "    )\n",
        "\n",
        "    agent_a = AgentA(name=\"AgentA\")\n",
        "    agent_b = AgentB(name=\"AgentB\")\n",
        "\n",
        "    # Create the SequentialAgent\n",
        "    sequential_agent = SequentialAgent(\n",
        "        name=\"SequentialAgent\", sub_agents=[agent_a, agent_b]\n",
        "    )\n",
        "\n",
        "    # Create InvocationContext\n",
        "    ctx = InvocationContext(\n",
        "        invocation_id=new_invocation_context_id(),\n",
        "        session_service=session_service,\n",
        "        session=session,\n",
        "        agent=sequential_agent,\n",
        "        user_content=types.Content(parts=[types.Part(text=\"execute\")]),\n",
        "    )\n",
        "\n",
        "    # Run the SequentialAgent\n",
        "    async for event in sequential_agent.run_async(ctx):\n",
        "        if event.content and event.content.parts:\n",
        "            print(f\"Event: {event.author}: {event.content.parts[0].text}\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDROM_P-Alpt"
      },
      "source": [
        "### Sequence with LLMAgent and simple runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPHz5Cyv_z8F",
        "outputId": "5aed0837-587e-4770-f28c-61f7c30e5518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent Response:  Agent A: Starting...\n",
            "\n",
            "Agent Response:  Agent B: Starting...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google.adk.agents.sequential_agent import SequentialAgent\n",
        "from google.adk.agents.llm_agent import LlmAgent\n",
        "from google.genai import types\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "\n",
        "\n",
        "APP_NAME = \"sequential_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"sequential_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "\n",
        "agent_a = LlmAgent(\n",
        "    name=\"AgentA\",\n",
        "    model=GEMINI_2_FLASH,\n",
        "    instruction=\"You are Agent A. Respond with 'Agent A: Starting...'\",\n",
        "    output_key=\"agent_a\",\n",
        ")\n",
        "\n",
        "agent_b = LlmAgent(\n",
        "    name=\"AgentB\",\n",
        "    model=GEMINI_2_FLASH,\n",
        "    instruction=\"You are Agent B. Respond with 'Agent B: Starting...'\",\n",
        ")\n",
        "\n",
        "# Create the SequentialAgent\n",
        "sequential_agent = SequentialAgent(\n",
        "    name=\"SequentialAgent\", sub_agents=[agent_a, agent_b]\n",
        ")\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(\n",
        "    agent=sequential_agent, app_name=APP_NAME, session_service=session_service\n",
        ")\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "def call_agent(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n",
        "\n",
        "\n",
        "call_agent(\"execute\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVS5bHjqO0sD"
      },
      "source": [
        "## Multi-Agent - LoopAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrsvPMqDAu79"
      },
      "source": [
        "### LoopAgent with Simple Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUYDIdsxAuvu",
        "outputId": "ce93c375-a026-44bb-d48f-99e434763d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent Response:  Agent A: Starting...\n",
            "\n",
            "Agent Response:  Agent B: Starting...\n",
            "\n",
            "Agent Response:  Agent A: Acknowledged. Agent B has started.\n",
            "\n",
            "Agent Response:  Agent B: Acknowledged.\n",
            "\n",
            "Agent Response:  Agent A: Acknowledged. Agent B has acknowledged.\n",
            "\n",
            "Agent Response:  Agent B: Acknowledged.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google.adk.agents.loop_agent import LoopAgent\n",
        "from google.adk.agents.llm_agent import LlmAgent\n",
        "from google.genai import types\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "\n",
        "\n",
        "APP_NAME = \"loop_app\"\n",
        "USER_ID = \"12345\"\n",
        "SESSION_ID = \"123344\"\n",
        "AGENT_NAME = \"loop_agent\"\n",
        "GEMINI_2_FLASH = \"gemini-2.0-flash-001\"\n",
        "\n",
        "agent_a = LlmAgent(\n",
        "    name=\"AgentA\",\n",
        "    model=GEMINI_2_FLASH,\n",
        "    instruction=\"You are Agent A. Respond with 'Agent A: Starting...'\",\n",
        ")\n",
        "\n",
        "agent_b = LlmAgent(\n",
        "    name=\"AgentB\",\n",
        "    model=GEMINI_2_FLASH,\n",
        "    instruction=\"You are Agent B. Respond with 'Agent B: Starting...'\",\n",
        ")\n",
        "\n",
        "# Create the LoopAgent\n",
        "loop_agent = LoopAgent(\n",
        "    name=\"LoopAgent\", sub_agents=[agent_a, agent_b], max_iterations=3\n",
        ")\n",
        "\n",
        "\n",
        "# Session and Runner\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        ")\n",
        "runner = Runner(agent=loop_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "\n",
        "# Agent Interaction\n",
        "def call_agent(query):\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(\"Agent Response: \", final_response)\n",
        "\n",
        "\n",
        "call_agent(\"execute\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxOrUPQkO34F"
      },
      "source": [
        "### LoopAgent with InnvocationContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCaz2BtMO4Nu",
        "outputId": "9277dab0-af9e-4f5d-c038-e698e90995fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event: AgentA: Agent A: Starting...\n",
            "Event: AgentA: Agent A: Finishing...\n",
            "Event: AgentB: Agent B: Starting...\n",
            "Event: AgentB: Agent B: Finishing...\n",
            "Event: AgentA: Agent A: Starting...\n",
            "Event: AgentA: Agent A: Finishing...\n",
            "Event: AgentB: Agent B: Starting...\n",
            "Event: AgentB: Agent B: Finishing...\n"
          ]
        }
      ],
      "source": [
        "from google.adk.agents.loop_agent import LoopAgent\n",
        "\n",
        "\n",
        "class AgentA(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Starting...\")]),\n",
        "        )\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "class AgentB(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Starting...\")]),\n",
        "        )\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "async def main():\n",
        "    # Create a session\n",
        "    session_service = InMemorySessionService()\n",
        "    session: Session = session_service.create_session(\n",
        "        app_name=\"test_app\", user_id=\"test_user\"\n",
        "    )\n",
        "\n",
        "    agent_a = AgentA(name=\"AgentA\")\n",
        "    agent_b = AgentB(name=\"AgentB\")\n",
        "\n",
        "    # Create the LoopAgent\n",
        "    loop_agent = LoopAgent(\n",
        "        name=\"LoopAgent\", sub_agents=[agent_a, agent_b], max_iterations=2\n",
        "    )\n",
        "\n",
        "    # Create InvocationContext\n",
        "    ctx = InvocationContext(\n",
        "        invocation_id=new_invocation_context_id(),\n",
        "        session_service=session_service,\n",
        "        session=session,\n",
        "        agent=loop_agent,\n",
        "        user_content=types.Content(parts=[types.Part(text=\"execute\")]),\n",
        "    )\n",
        "\n",
        "    # Run the LoopAgent\n",
        "    async for event in loop_agent.run_async(ctx):\n",
        "        if event.content and event.content.parts:\n",
        "            print(f\"Event: {event.author}: {event.content.parts[0].text}\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcBLz-NZPHvi"
      },
      "source": [
        "### Stop Condition with EventActions=Escalation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J42_PTYgPJQN",
        "outputId": "ed275827-c79a-498f-f5bc-cfcb37987704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event: AgentA: Agent A: Starting...\n",
            "Event: AgentA: Agent A: Finishing...\n",
            "Event: AgentB: Agent B: Starting...\n",
            "Event: AgentB: Agent B: Finishing...\n"
          ]
        }
      ],
      "source": [
        "from google.adk.agents.loop_agent import LoopAgent\n",
        "from google.adk.events.event_actions import EventActions\n",
        "\n",
        "\n",
        "class AgentA(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Starting...\")]),\n",
        "        )\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "class AgentB(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Starting...\")]),\n",
        "        )\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Finishing...\")]),\n",
        "            actions=EventActions(escalate=True),\n",
        "        )\n",
        "\n",
        "\n",
        "async def main():\n",
        "    # Create a session\n",
        "    session_service = InMemorySessionService()\n",
        "    session: Session = session_service.create_session(\n",
        "        app_name=\"test_app\", user_id=\"test_user\"\n",
        "    )\n",
        "\n",
        "    agent_a = AgentA(name=\"AgentA\")\n",
        "    agent_b = AgentB(name=\"AgentB\")\n",
        "\n",
        "    # Create the LoopAgent\n",
        "    loop_agent = LoopAgent(\n",
        "        name=\"LoopAgent\", sub_agents=[agent_a, agent_b], max_iterations=10\n",
        "    )\n",
        "\n",
        "    # Create InvocationContext\n",
        "    ctx = InvocationContext(\n",
        "        invocation_id=new_invocation_context_id(),\n",
        "        session_service=session_service,\n",
        "        session=session,\n",
        "        agent=loop_agent,\n",
        "        user_content=types.Content(parts=[types.Part(text=\"execute\")]),\n",
        "    )\n",
        "\n",
        "    # Run the LoopAgent\n",
        "    async for event in loop_agent.run_async(ctx):\n",
        "        if event.content and event.content.parts:\n",
        "            print(f\"Event: {event.author}: {event.content.parts[0].text}\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21opVatuSEME"
      },
      "source": [
        "### Escalation with Condition - defined in state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOCPRwuZSEfD",
        "outputId": "c86d0a6d-4e7b-447f-ad79-ec957d34e8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event: AgentA: Agent A: Starting...\n",
            "Event: AgentA: Agent A: Finishing...\n",
            "Event: AgentB: Agent B: Starting...\n",
            "Event: AgentB: Agent B: Finishing...\n"
          ]
        }
      ],
      "source": [
        "class AgentA(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Starting...\")]),\n",
        "        )\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "class AgentB(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Starting...\")]),\n",
        "        )\n",
        "\n",
        "        # Example condition: Escalate if session state has a key 'escalate_agent_b'\n",
        "        escalate = ctx.session.state.get(\"escalate_agent_b\", False)\n",
        "\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Finishing...\")]),\n",
        "            actions=EventActions(escalate=escalate),\n",
        "        )\n",
        "\n",
        "\n",
        "async def main():\n",
        "    # Create a session\n",
        "    session_service = InMemorySessionService()\n",
        "    session: Session = session_service.create_session(\n",
        "        app_name=\"test_app\", user_id=\"test_user\"\n",
        "    )\n",
        "\n",
        "    agent_a = AgentA(name=\"AgentA\")\n",
        "    agent_b = AgentB(name=\"AgentB\")\n",
        "\n",
        "    # Create the LoopAgent\n",
        "    loop_agent = LoopAgent(\n",
        "        name=\"LoopAgent\", sub_agents=[agent_a, agent_b], max_iterations=3\n",
        "    )\n",
        "\n",
        "    # Create InvocationContext\n",
        "    ctx = InvocationContext(\n",
        "        invocation_id=new_invocation_context_id(),\n",
        "        session_service=session_service,\n",
        "        session=session,\n",
        "        agent=loop_agent,\n",
        "        user_content=types.Content(parts=[types.Part(text=\"execute\")]),\n",
        "    )\n",
        "\n",
        "    # Example: Set a condition to escalate\n",
        "    ctx.session.state[\"escalate_agent_b\"] = True\n",
        "\n",
        "    # Run the LoopAgent\n",
        "    async for event in loop_agent.run_async(ctx):\n",
        "        if event.content and event.content.parts:\n",
        "            print(f\"Event: {event.author}: {event.content.parts[0].text}\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu7fJ5QIUECc"
      },
      "source": [
        "## ParallelAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3iVDqUdUGdx"
      },
      "source": [
        "### Simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgqJ9rzxUGo_",
        "outputId": "6c2db6e1-53a4-4de6-ef4a-f45c741b3929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event: AgentA: Agent A: Starting...\n",
            "Event: AgentB: Agent B: Starting...\n",
            "Event: AgentA: Agent A: Finishing...\n",
            "Event: AgentB: Agent B: Finishing...\n"
          ]
        }
      ],
      "source": [
        "from google.adk.agents.parallel_agent import ParallelAgent\n",
        "\n",
        "\n",
        "class AgentA(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Starting...\")]),\n",
        "        )\n",
        "        await asyncio.sleep(1)\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "class AgentB(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Starting...\")]),\n",
        "        )\n",
        "        await asyncio.sleep(2)\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "async def main():\n",
        "    # Create a session\n",
        "    session_service = InMemorySessionService()\n",
        "    session: Session = session_service.create_session(\n",
        "        app_name=\"test_app\", user_id=\"test_user\"\n",
        "    )\n",
        "\n",
        "    agent_a = AgentA(name=\"AgentA\")\n",
        "    agent_b = AgentB(name=\"AgentB\")\n",
        "\n",
        "    # Create the ParallelAgent\n",
        "    parallel_agent = ParallelAgent(name=\"ParallelAgent\", sub_agents=[agent_a, agent_b])\n",
        "\n",
        "    # Create InvocationContext\n",
        "    ctx = InvocationContext(\n",
        "        invocation_id=new_invocation_context_id(),\n",
        "        session_service=session_service,\n",
        "        session=session,\n",
        "        agent=parallel_agent,\n",
        "        user_content=types.Content(parts=[types.Part(text=\"execute\")]),\n",
        "    )\n",
        "\n",
        "    # Run the ParallelAgent\n",
        "    async for event in parallel_agent.run_async(ctx):\n",
        "        if event.content and event.content.parts:\n",
        "            print(f\"Event: {event.author}: {event.content.parts[0].text}\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2iStmHFUcRj"
      },
      "source": [
        "### Shared State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1EZZfy4UdpK",
        "outputId": "f85a2373-550b-4210-b8dc-addea1823e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event: AgentB: Agent B: Starting...\n",
            "Event: AgentA: Agent A: Starting...\n",
            "Event: AgentA: Agent A: Finishing...\n",
            "Event: AgentB: Agent B: Finishing... Received: Data from Agent A\n"
          ]
        }
      ],
      "source": [
        "class AgentA(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Starting...\")]),\n",
        "        )\n",
        "        await asyncio.sleep(1)\n",
        "        ctx.session.state[\"shared_data\"] = \"Data from Agent A\"\n",
        "        yield Event(\n",
        "            author=\"AgentA\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent A: Finishing...\")]),\n",
        "        )\n",
        "\n",
        "\n",
        "class AgentB(BaseAgent):\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(parts=[types.Part(text=\"Agent B: Starting...\")]),\n",
        "        )\n",
        "        await asyncio.sleep(2)\n",
        "        shared_data = ctx.session.state.get(\"shared_data\", \"No data from Agent A\")\n",
        "        yield Event(\n",
        "            author=\"AgentB\",\n",
        "            content=types.Content(\n",
        "                parts=[\n",
        "                    types.Part(text=f\"Agent B: Finishing... Received: {shared_data}\")\n",
        "                ]\n",
        "            ),\n",
        "        )\n",
        "\n",
        "\n",
        "async def main():\n",
        "    # Create a session\n",
        "    session_service = InMemorySessionService()\n",
        "    session: Session = session_service.create_session(\n",
        "        app_name=\"test_app\", user_id=\"test_user\"\n",
        "    )\n",
        "\n",
        "    agent_a = AgentA(name=\"AgentA\")\n",
        "    agent_b = AgentB(name=\"AgentB\")\n",
        "\n",
        "    # Create the ParallelAgent\n",
        "    parallel_agent = ParallelAgent(name=\"ParallelAgent\", sub_agents=[agent_a, agent_b])\n",
        "\n",
        "    # Create InvocationContext\n",
        "    ctx = InvocationContext(\n",
        "        invocation_id=new_invocation_context_id(),\n",
        "        session_service=session_service,\n",
        "        session=session,\n",
        "        agent=parallel_agent,\n",
        "        user_content=types.Content(parts=[types.Part(text=\"execute\")]),\n",
        "    )\n",
        "\n",
        "    # Run the ParallelAgent\n",
        "    async for event in parallel_agent.run_async(ctx):\n",
        "        if event.content and event.content.parts:\n",
        "            print(f\"Event: {event.author}: {event.content.parts[0].text}\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vfkz0jeeobT"
      },
      "source": [
        "## CustomAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb4lAAD4eo77",
        "outputId": "f72e46b3-fcb4-464d-9fda-0e0eee87e240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event: Hello from Custom Agent!\n"
          ]
        }
      ],
      "source": [
        "class CustomAgent(BaseAgent):\n",
        "    \"\"\"A custom agent that generates a simple text message.\"\"\"\n",
        "\n",
        "    @override\n",
        "    async def _run_async_impl(\n",
        "        self, ctx: InvocationContext\n",
        "    ) -> AsyncGenerator[Event, None]:\n",
        "        yield Event(\n",
        "            invocation_id=ctx.invocation_id,\n",
        "            author=self.name,\n",
        "            content=types.Content(\n",
        "                parts=[types.Part.from_text(text=\"Hello from Custom Agent!\")],\n",
        "            ),\n",
        "        )\n",
        "\n",
        "\n",
        "async def main():\n",
        "    # Create a custom agent instance\n",
        "    custom_agent = CustomAgent(name=\"CustomAgent\", description=\"A custom agent\")\n",
        "\n",
        "    # Create a session service\n",
        "    session_service = InMemorySessionService()\n",
        "\n",
        "    # Create a session\n",
        "    session = session_service.create_session(\n",
        "        app_name=\"demo_app\", user_id=\"test_user\", session_id=\"test_session\"\n",
        "    )\n",
        "\n",
        "    # Create a runner instance\n",
        "    runner = Runner(\n",
        "        app_name=\"demo_app\",\n",
        "        agent=custom_agent,\n",
        "        session_service=session_service,\n",
        "    )\n",
        "\n",
        "    # Run the agent\n",
        "    async for event in runner.run_async(\n",
        "        user_id=\"test_user\",\n",
        "        session_id=\"test_session\",\n",
        "        new_message=types.Content(\n",
        "            parts=[types.Part.from_text(text=\"Hi, how are you?\")]\n",
        "        ),\n",
        "    ):\n",
        "        print(f\"Event: {event.content.parts[0].text}\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
